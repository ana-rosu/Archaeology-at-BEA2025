{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebabde-0876-45e4-bbde-8712364e8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea4029e-5c1b-4a18-850b-0f1877defdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418aed86-937f-45d0-ac9c-1e4365e981e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accbe1e8-04ee-4eed-8393-1f013634bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LABEL = 'mistake_identification'\n",
    "MODEL = \"roberta-large\"\n",
    "train_df = pd.read_csv(\"data/mistake_identification_train.csv\")\n",
    "val_df = pd.read_csv(\"data/mistake_identification_val.csv\")\n",
    "\n",
    "full_df = pd.concat([train_df, val_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5609a98b-2b95-4d76-9a76-103fba03855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea06837f-6a58-4e04-8478-76f9a44b90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_weights(train_df, label, normalized=False):\n",
    "  label_counts = Counter(train_df[label])\n",
    "  total = sum(label_counts.values())\n",
    "  weights = torch.tensor([total / label_counts.get(cls, 1) for cls in range(3)])\n",
    "  if normalized:\n",
    "    weights_normalized = weights / weights.mean()\n",
    "    return weights_normalized\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59326a6c-deed-4353-abfe-c336d533b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_equal = torch.tensor([1.0, 1.0, 1.0])\n",
    "weights = get_weights(train_df, LABEL)\n",
    "weights_normalized = get_weights(train_df, LABEL, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edff4594-b51e-4e5b-9a9e-b39fed13e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([ 6.6768, 13.8671,  1.2852])\n",
      "tensor([0.9176, 1.9058, 0.1766])\n"
     ]
    }
   ],
   "source": [
    "print(alpha_equal)\n",
    "print(weights)\n",
    "print(weights_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8c5315-fcbf-4820-aafd-cd336ec63bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = F.log_softmax(inputs, dim=-1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = logpt.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        pt = pt.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            at = self.alpha.to(targets.device).gather(0, targets)\n",
    "            logpt = logpt * at\n",
    "\n",
    "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03d73e8-3c5b-4a2d-aebf-4dce64a36236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class StratifiedBatchSampler(Sampler):\n",
    "    def __init__(self, labels, batch_size, shuffle=True):\n",
    "        self.labels = np.array(labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.label_to_indices = defaultdict(list)\n",
    "\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            self.label_to_indices[label].append(idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        all_batches = []\n",
    "\n",
    "        # Stratify each batch\n",
    "        min_class_count = min([len(v) for v in self.label_to_indices.values()])\n",
    "        n_batches = len(self.labels) // self.batch_size\n",
    "\n",
    "        # Estimate proportions\n",
    "        proportions = {\n",
    "            k: len(v) / len(self.labels)\n",
    "            for k, v in self.label_to_indices.items()\n",
    "        }\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            batch = []\n",
    "            for cls, prob in proportions.items():\n",
    "                n_cls = max(1, int(prob * self.batch_size))\n",
    "                chosen = random.sample(self.label_to_indices[cls], min(n_cls, len(self.label_to_indices[cls])))\n",
    "                batch.extend(chosen)\n",
    "            if self.shuffle:\n",
    "                random.shuffle(batch)\n",
    "            all_batches.append(batch[:self.batch_size])\n",
    "\n",
    "        random.shuffle(all_batches)\n",
    "        return iter([i for batch in all_batches for i in batch])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99b5543d-87b3-4b4a-8dc8-fa50dda9bdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, loss_type=\"cross_entropy\", **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_type = loss_type\n",
    "        self.weights = weights\n",
    "        self.focal_loss = FocalLoss(alpha=alpha if loss_type == \"focal\" else None)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "      labels = inputs.pop(\"labels\")\n",
    "      outputs = model(**inputs)\n",
    "      logits = outputs.logits\n",
    "\n",
    "      if self.loss_type == \"focal\":\n",
    "          loss = self.focal_loss(logits, labels)\n",
    "      elif self.loss_type == \"weighted\":\n",
    "          w = self.weights.to(logits.device)\n",
    "          loss = F.cross_entropy(logits, labels, weight=w)\n",
    "      else:\n",
    "          loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "      return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    # Allows stratified batches - comment out if you don t want stratified batches\n",
    "    # def get_train_dataloader(self):\n",
    "    #     if self.train_dataset is None:\n",
    "    #         raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "    #     # Extract labels from dataset\n",
    "    #     labels = self.train_dataset['labels']\n",
    "\n",
    "    #     sampler = StratifiedBatchSampler(\n",
    "    #         labels=labels,\n",
    "    #         batch_size=self.args.train_batch_size,\n",
    "    #         shuffle=True\n",
    "    #     )\n",
    "\n",
    "    #     return DataLoader(\n",
    "    #         self.train_dataset,\n",
    "    #         batch_size=self.args.train_batch_size,\n",
    "    #         sampler=sampler,\n",
    "    #         collate_fn=self.data_collator,\n",
    "    #         drop_last=self.args.dataloader_drop_last,\n",
    "    #         num_workers=self.args.dataloader_num_workers,\n",
    "    #     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d8a80f-2c07-4d62-a180-64ecd111011b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1456326944.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    TODO: adjust max_length based on 95th percentile for each case\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "TODO: adjust max_length based on 95th percentile for each case\n",
    "\n",
    "TODO: prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf745be-7b60-44c6-a38b-65b344df9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL)\n",
    "def tokenize(batch, use_context=True):\n",
    "    if use_context:\n",
    "        text1 = [f\"Student: {x}\" for x in batch['last_student_turn']]\n",
    "        text2 = [f\"Tutor: {x}\" for x in batch['response']]\n",
    "        return tokenizer(text1, text2, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    else:\n",
    "        text = [x for x in batch['response']]\n",
    "        return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "from functools import partial\n",
    "tokenize_with_context = partial(tokenize, use_context=True)\n",
    "tokenize_no_context = partial(tokenize, use_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97625181-3bb9-483d-90c9-f3af27a9c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100% 1983/1983 [00:00<00:00, 4912.84 examples/s]\n",
      "Map: 100% 493/493 [00:00<00:00, 4655.66 examples/s]\n",
      "Map: 100% 1983/1983 [00:00<00:00, 6145.22 examples/s]\n",
      "Map: 100% 493/493 [00:00<00:00, 6048.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds_context = Dataset.from_pandas(train_df[[\"last_student_turn\", \"response\", \"mistake_identification\"]].rename(columns={\"mistake_identification\": \"labels\"}))\n",
    "val_ds_context = Dataset.from_pandas(val_df[[\"last_student_turn\", \"response\", \"mistake_identification\"]].rename(columns={\"mistake_identification\": \"labels\"}))\n",
    "\n",
    "train_ds_context = train_ds_context.map(tokenize_with_context, batched=True)\n",
    "val_ds_context = val_ds_context.map(tokenize_with_context, batched=True)\n",
    "\n",
    "train_ds_nocontext = Dataset.from_pandas(train_df[[\"last_student_turn\", \"response\", \"mistake_identification\"]].rename(columns={\"mistake_identification\": \"labels\"}))\n",
    "val_ds_nocontext = Dataset.from_pandas(val_df[[\"last_student_turn\", \"response\", \"mistake_identification\"]].rename(columns={\"mistake_identification\": \"labels\"}))\n",
    "\n",
    "train_ds_nocontext = train_ds_nocontext.map(tokenize_no_context, batched=True)\n",
    "val_ds_nocontext = val_ds_nocontext.map(tokenize_no_context, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "686ffa34-bf96-4ba7-ad4d-69bf5f7cf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "# Metrics\n",
    "def compute_lenient_metrics(y_true, y_pred):\n",
    "    def to_lenient(y): return np.where(np.isin(y, [1, 2]), 1, 0)\n",
    "    y_true_len = to_lenient(y_true)\n",
    "    y_pred_len = to_lenient(y_pred)\n",
    "\n",
    "    acc = balanced_accuracy_score(y_true_len, y_pred_len)\n",
    "    f1 = f1_score(y_true_len, y_pred_len, average=\"binary\")\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = balanced_accuracy_score(labels, preds)\n",
    "    len_acc, len_f1 = compute_lenient_metrics(labels, preds)\n",
    "    conf = confusion_matrix(labels, preds)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf)\n",
    "    # print(classification_report(labels, preds, target_names=[\"No\", \"TSE\", \"Yes\"]))\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"lenient_accuracy\": len_acc,\n",
    "        \"lenient_f1\": len_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f92d122-7107-40b7-81e3-395f092baf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "# Model\n",
    "model = RobertaForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n",
    "\n",
    "# Training\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./outputs_mistake_id_roberta\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,                     # recommended for RoBERTa-large\n",
    "    per_device_train_batch_size=8,          # reduce if OOM\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,                     \n",
    "    warmup_ratio=0.1,                       # important for RoBERTa stability\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_roberta\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    save_total_limit=2,\n",
    "    lr_scheduler_type=\"linear\",             # linear or cosine both work well\n",
    "    fp16=torch.cuda.is_available(),         \n",
    "    gradient_checkpointing=True,            # helps reduce memory\n",
    "    report_to=\"none\",                       # or \"tensorboard\"/\"wandb\" if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a080aa-a5bd-423d-822a-feb51c5338f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Running: context=True, seed=42 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Define trainer\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m RobertaForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mCustomTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStoppingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     40\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36mCustomTrainer.__init__\u001b[0;34m(self, loss_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, loss_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_entropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_type \u001b[38;5;241m=\u001b[39m loss_type\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m weights\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:614\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    613\u001b[0m ):\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:901\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 901\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3712\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3708\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3709\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3710\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3711\u001b[0m         )\n\u001b[0;32m-> 3712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, random\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "seeds = [42, 52, 62, 88, 99]\n",
    "contexts = [True, False]\n",
    "\n",
    "for use_context in contexts:\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n==== Running: context={use_context}, seed={seed} ====\")\n",
    "\n",
    "        # Fix seed\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Tokenize\n",
    "        train_ds = train_ds_context if use_context else train_ds_nocontext\n",
    "        val_ds = val_ds_context if use_context else val_ds_nocontext\n",
    "\n",
    "        # Define trainer\n",
    "        model = RobertaForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n",
    "\n",
    "        trainer = CustomTrainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=train_ds,\n",
    "            eval_dataset=val_ds,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "        \"context\": use_context,\n",
    "        \"seed\": seed,\n",
    "        \"loss\": metrics.get(\"eval_loss\", -1),\n",
    "        \"macro_f1\": metrics.get(\"eval_macro_f1\", -1),\n",
    "        \"lenient_f1\": metrics.get(\"eval_lenient_f1\", -1),\n",
    "        \"accuracy\": metrics.get(\"eval_accuracy\", -1),\n",
    "        \"lenient_accuracy\": metrics.get(\"eval_lenient_accuracy\", -1)\n",
    "      })\n",
    "\n",
    "\n",
    "# Create result DataFrame\n",
    "df_context = pd.DataFrame(results)\n",
    "df_context.to_csv(\"results_context_comparison.csv\", index=False)\n",
    "print(\"\\n All experiments complete. Results saved to 'results_context_comparison.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9844268d-9460-4f60-9e9e-42d3e96988b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>seed</th>\n",
       "      <th>loss</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>lenient_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lenient_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.700287</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.894523</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "      <td>0.536447</td>\n",
       "      <td>0.687964</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.888438</td>\n",
       "      <td>0.937120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>0.593741</td>\n",
       "      <td>0.675755</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>0.886410</td>\n",
       "      <td>0.935091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "      <td>0.558683</td>\n",
       "      <td>0.673045</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.935091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>0.520346</td>\n",
       "      <td>0.676742</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.894523</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>0.532795</td>\n",
       "      <td>0.629411</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.876268</td>\n",
       "      <td>0.933063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>0.686720</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.886410</td>\n",
       "      <td>0.935091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>62</td>\n",
       "      <td>0.489638</td>\n",
       "      <td>0.649745</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.937120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0.956419</td>\n",
       "      <td>0.868154</td>\n",
       "      <td>0.924949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>0.515535</td>\n",
       "      <td>0.730862</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>0.888438</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context  seed      loss  macro_f1  lenient_f1  accuracy  lenient_accuracy\n",
       "0     True    42  0.555945  0.700287    0.965842  0.894523          0.941176\n",
       "1     True    52  0.536447  0.687964    0.963572  0.888438          0.937120\n",
       "2     True    62  0.593741  0.675755    0.962175  0.886410          0.935091\n",
       "3     True    88  0.558683  0.673045    0.962264  0.882353          0.935091\n",
       "4     True    99  0.520346  0.676742    0.965842  0.894523          0.941176\n",
       "5    False    42  0.532795  0.629411    0.961039  0.876268          0.933063\n",
       "6    False    52  0.521937  0.686720    0.962264  0.886410          0.935091\n",
       "7    False    62  0.489638  0.649745    0.963400  0.882353          0.937120\n",
       "8    False    88  0.546296  0.629348    0.956419  0.868154          0.924949\n",
       "9    False    99  0.515535  0.730862    0.965922  0.888438          0.941176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d535b40d-00ae-4a12-a39c-54f311e8c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAO4tJREFUeJzt3XtclGX+//H3DMqAiHgAERWEJMtSUzFdNTyFa66rq7sZpXmqtFUJlQ7q+lXTUrKDa3bQ6OuxMklry8I0Iw/gYTVdLbU8C24KaiYoKihz//7ox3ydAEMODnC/no/H/ai57uu+5nON4Ly97+uesRiGYQgAAMBErK4uAAAA4FYjAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEoVcHBwRo6dGiR+/75z38u24IqscWLF8tisej48eNF7vvtt9+WfWFABUAAQqWU95e9xWJRcnJyvv2GYSgwMFAWi6VCvgEHBwc75vfb7cqVK5KkixcvaurUqXrggQdUu3ZtWSwWLV68+JbXun//fj3//PNFepO+lZYtW6Y5c+a4uoxS9/bbb7vkz7ms3Kr5bNmyRc8//7zOnz9f5s+F8qGKqwsAypKHh4eWLVum++67z6l948aN+u9//yubzeaiykquZcuWevrpp/O1u7u7S5LOnj2r6dOnKygoSPfcc482bNhwS+o6cOCArNb/+7fV/v37NW3aNHXp0kXBwcG3pIaiWLZsmfbu3auxY8e6upRiGzRokB5++GGnn+O3335bvr6+RT4LV97dqvls2bJF06ZN09ChQ1WzZs0yfS6UDwQgVGp/+tOftGLFCs2dO1dVqvzfj/uyZcsUFhams2fP3tJ6DMPQlStX5OnpWeKxGjRooEcffbTQ/QEBATp16pTq1aunb7/9Vvfee2+Jn7MoKnKorGjc3Nzk5ubm6jKAColLYKjUHnnkEf38889at26doy0nJ0crV67UgAEDCjzm1VdfVYcOHVSnTh15enoqLCxMK1euLLDv+++/r7Zt26patWqqVauWOnXqpK+++sqxP2+Ny9q1a9WmTRt5enrqnXfekSQdPXpU/fv3V+3atVWtWjX94Q9/UEJCQqnN3WazqV69esU6dtWqVbJYLPruu+8cbR9//LEsFov++te/OvVt2rSpIiMjHY+vXwO0ePFi9e/fX5LUtWtXx2W6356NSk5OVtu2beXh4aHbbrtNS5cuzVdTUV6vwtbEbNiwwel5u3TpooSEBKWkpDhqutHZqWbNmqlr16752u12uxo0aKAHH3zQ0bZ8+XKFhYXJ29tbNWrUUPPmzfX6668XOrYktW7dOt/r2rx583x/BvHx8bJYLPrhhx8KnG9wcLD27dunjRs3OubVpUsXp3Gzs7MVExMjPz8/eXl5qV+/fjpz5swN68vz448/6qGHHpKfn588PT11xx13aNKkSU59/vOf/6hnz56qUaOGqlevrvvvv1/btm1z6pNX9+bNm29Yy+/N5/z58xo7dqwCAwNls9kUGhqqWbNmyW63S/r1Hxxdu3aVn5+fTp8+7TguJydHzZs3V+PGjZWVlaXnn39ezz77rCQpJCTE8Vzl7bItShcBCJVacHCw2rdvrw8//NDR9uWXXyojI0MPP/xwgce8/vrratWqlaZPn66ZM2eqSpUq6t+/f74322nTpmnQoEGqWrWqpk+frmnTpikwMFDffPONU78DBw7okUceUffu3fX666+rZcuWSk9PV4cOHbR27VqNGjVKM2bM0JUrV9SnTx/961//KtLcrl69qrNnzzptly5duslXqGD33XefLBaLNm3a5GhLSkqS1Wp1WlN15swZ/fjjj+rUqVOB43Tq1EnR0dGSpH/84x9677339N5776lp06aOPocPH9aDDz6o7t2767XXXlOtWrU0dOhQ7du3z9GnNF6v602aNEktW7aUr6+vo6YbrQeKjIzUpk2blJaW5tSenJyskydPOn6W1q1bp0ceeUS1atXSrFmz9NJLL6lLly7avHnzDesJDw93el3PnTunffv2yWq1KikpydGelJQkPz8/p9fvenPmzFHDhg115513Oub124Dy1FNPac+ePZo6dapGjhypzz//XFFRUTesT5K+++47tWvXTt98842GDx+u119/XX379tXnn3/u6LNv3z6Fh4drz549eu655zR58mQdO3ZMXbp00b///e98Y/5eLTeaz6VLl9S5c2e9//77Gjx4sObOnauOHTtq4sSJiomJkSRZLBYtXLhQV65c0d///nfHuFOnTtW+ffu0aNEieXl56a9//aseeeQRSdI///lPx3P5+fn97uuCCswAKqFFixYZkowdO3YYb775puHt7W1cunTJMAzD6N+/v9G1a1fDMAyjUaNGRq9evZyOzeuXJycnx2jWrJnRrVs3R9uhQ4cMq9Vq9OvXz8jNzXXqb7fbHf/fqFEjQ5KxZs0apz5jx441JBlJSUmOtgsXLhghISFGcHBwvjF/K2/c325Tp04tsP+OHTsMScaiRYtuOO717r77buOhhx5yPG7durXRv39/Q5Lxww8/GIZhGJ988okhydizZ49TbUOGDHE8XrFihSHJWL9+faHz2LRpk6Pt9OnThs1mM55++mlHW1Ffr7w/92PHjjk9z/r16/PV0KtXL6NRo0ZFei0OHDhgSDLeeOMNp/ZRo0YZ1atXd/zMjBkzxqhRo4Zx7dq1Io2bJ+812r9/v2EYhrFq1SrDZrMZffr0MSIjIx39WrRoYfTr18/xuKD53n333Ubnzp3zPUde34iICKef0XHjxhlubm7G+fPnb1hjp06dDG9vbyMlJcWp/fqx+vbta7i7uxtHjhxxtJ08edLw9vY2OnXqVKxaCpvPCy+8YHh5eRkHDx50ap8wYYLh5uZmpKamOtreeecdQ5Lx/vvvG9u2bTPc3NyMsWPHOh33yiuvFPizg8qLM0Co9B566CFdvnxZX3zxhS5cuKAvvvii0MtfkpzW5/zyyy/KyMhQeHi4du3a5Wj/9NNPZbfbNWXKFKcFv9Kv/+q8XkhIiHr06OHUtnr1arVt29ZpcXb16tU1YsQIHT9+XPv37//debVr107r1q1z2gYPHvy7xxVVeHi44+zDhQsXtGfPHo0YMUK+vr6O9qSkJNWsWVPNmjUr9vPcddddCg8Pdzz28/PTHXfcoaNHjzraSuP1KokmTZqoZcuWio+Pd7Tl5uZq5cqV6t27t+NnpmbNmsrKynK65FoUefPPO+OWlJSke++9V927d3e81ufPn9fevXudXqviGDFihNPPaHh4uHJzc5WSklLoMWfOnNGmTZv02GOPKSgoyGlf3li5ubn66quv1LdvX912222O/QEBARowYICSk5OVmZlZ4lryrFixQuHh4apVq5bTWdCIiAjl5uY6nb0cMWKEevTooaeeekqDBg1S48aNNXPmzN99DlRuBCBUen5+foqIiNCyZcv0ySefKDc312nNxm998cUX+sMf/iAPDw/Vrl1bfn5+mjdvnjIyMhx9jhw5IqvVqrvuuut3nz8kJCRfW0pKiu6444587XmXNoryBuDr66uIiAin7fo3npIKDw/XqVOndPjwYW3ZskUWi0Xt27d3CkZJSUnq2LFjvhB4M377hipJtWrV0i+//OJ4XBqvV0lFRkZq8+bN+umnnyT9uq7o9OnTTuufRo0apSZNmqhnz55q2LChHnvsMa1Zs+Z3x/b399ftt9/u9LqGh4erU6dOOnnypI4eParNmzfLbreXOAD99vWuVauWJDm93r+VF0ZvFHTPnDmjS5cuFfrnZLfbdeLEiRLXkufQoUNas2aN/Pz8nLaIiAhJclrzI0kLFizQpUuXdOjQIS1evLhUbkRAxUYAgikMGDBAX375pebPn6+ePXsWeptrUlKS+vTpIw8PD7399ttavXq11q1bpwEDBsgwjGI9d0X9izbvbMumTZuUlJSk1q1by8vLyxGALl68qP/85z8lfkMu7C6m4rzevz37lic3N/emx/qtyMhIGYahFStWSJI++ugj+fj46IEHHnD0qVu3rnbv3q1Vq1apT58+Wr9+vXr27KkhQ4b87vj33XefkpKSdPnyZe3cuVPh4eFq1qyZatasqaSkJCUlJal69epq1apVieZRmq93SZWkFrvdru7du+c7C5q3/e1vf3Pqv2HDBmVnZ0uSvv/++5IXjwqP2+BhCv369dOTTz6pbdu2OV3G+K2PP/5YHh4eWrt2rdPt3IsWLXLq17hxY9ntdu3fv18tW7a86XoaNWqkAwcO5Gv/8ccfHftdLSgoSEFBQUpKStLRo0cdQadTp06KiYnRihUrlJubW+gC6DyFhZKbUdTXK+8Mwm8/zK6gM0Q3W1dISIjatm2r+Ph4RUVF6ZNPPlHfvn3z3fbv7u6u3r17q3fv3rLb7Ro1apTeeecdTZ48WaGhoYWOHx4erkWLFmn58uXKzc1Vhw4dZLVaHcHohx9+UIcOHX73tvfSeL1/K+/M4t69ewvt4+fnp2rVqhX652S1WhUYGHjTz13YfBo3bqyLFy86zvjcyKlTp/TUU0/pj3/8o9zd3fXMM8+oR48eTr9nZfG6oXzjDBBMoXr16po3b56ef/559e7du9B+bm5uslgsTmcMjh8/rk8//dSpX9++fWW1WjV9+nTHLbd5ivKv1z/96U/avn27tm7d6mjLyspSXFycgoODi3Rp7VYIDw/XN998o+3btzsCUMuWLeXt7a2XXnrJ8TEBN+Ll5SUpfyi5GUV9vRo3bixJTus/cnNzFRcXV2Bd11/WLIrIyEht27ZNCxcu1NmzZ50uf0nSzz//7PTYarWqRYsWkuQ4+1CYvNd31qxZatGihXx8fBztiYmJ+vbbb4t0ts3Ly6vUP83Yz89PnTp10sKFC5Wamuq0L+/n3c3NTX/84x/12WefOd0+np6e7vgw0ho1atz0cxc2n4ceekhbt27V2rVr8+07f/68rl275ng8fPhw2e12LViwQHFxcapSpYoef/xxp9/V0vg5RcXCGSCYRlEuQ/Tq1UuzZ8/WAw88oAEDBuj06dN66623FBoa6vR5LKGhoZo0aZJeeOEFhYeH669//atsNpt27Nih+vXrKzY29obPM2HCBH344Yfq2bOnoqOjVbt2bS1ZskTHjh3Txx9/XKI1Ndd78803df78eZ08eVKS9Pnnn+u///2vpF9vQc57ky1MeHi4PvjgA1ksFsclMTc3N8ct6V26dHF88nRhWrZsKTc3N82aNUsZGRmy2Wzq1q2b6tatW+R5FPX1uvvuu/WHP/xBEydO1Llz51S7dm0tX77c6c0wT1hYmOLj4xUTE6N7771X1atXv2E4ln59033mmWf0zDPPqHbt2vnOPjzxxBM6d+6cunXrpoYNGyolJUVvvPGGWrZsWeit63lCQ0NVr149HThwQE899ZSjvVOnTho/frwkFSkAhYWFad68eXrxxRcVGhqqunXrqlu3br973O+ZO3eu7rvvPrVu3VojRoxQSEiIjh8/roSEBO3evVuS9OKLL2rdunW67777NGrUKFWpUkXvvPOOsrOz9fLLLxfreQubz7PPPqtVq1bpz3/+s4YOHaqwsDBlZWXp+++/18qVK3X8+HH5+vpq0aJFSkhI0OLFi9WwYUNJ0htvvKFHH31U8+bN06hRoxzPI/36EQkPP/ywqlatqt69ezuCESoh192ABpSd62+Dv5GCboNfsGCBcfvttxs2m8248847jUWLFhlTp041Cvp1WbhwodGqVSvDZrMZtWrVMjp37mysW7fuhuPnOXLkiPHggw8aNWvWNDw8PIy2bdsaX3zxRZHmd6Nxf9tPBdwuryLe7rtv3z5DktG0aVOn9hdffNGQZEyePLnA57z+NnjDMIx3333XuO222ww3Nzen29ELm0fnzp3z3fpc1NfryJEjRkREhGGz2Qx/f3/jH//4h7Fu3bp8t8FfvHjRGDBggFGzZk1DUpFvie/YsaMhyXjiiSfy7Vu5cqXxxz/+0ahbt67h7u5uBAUFGU8++aRx6tSpIo2d9zED8fHxjracnByjWrVqhru7u3H58mWn/gXdBp+Wlmb06tXL8Pb2NiQ5XsfCficK+oiAwuzdu9fo16+f48/gjjvuyPczsGvXLqNHjx5G9erVjWrVqhldu3Y1tmzZUmDdRamlsPkYxq8fhTBx4kQjNDTUcHd3N3x9fY0OHToYr776qpGTk2OcOHHC8PHxMXr37p1vLv369TO8vLyMo0ePOtpeeOEFo0GDBobVauWWeBOwGIYLVr4BAAC4EGuAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6fBBiAWw2+06efKkvL29+Xh0AAAqCMMwdOHCBdWvX/93P1CWAFSAkydPFus7awAAgOudOHHC8cnfhSEAFcDb21vSry9gcb67BgAA3HqZmZkKDAx0vI/fCAGoAHmXvWrUqEEAAgCgginK8hUWQQMAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANPh2+BRIleuXFFqaqqry8B1goKC5OHh4eoyAKBcIwChRFJTUzVixAhXl4HrxMXFqUmTJq4uAwDKNQIQSiQoKEhxcXGuLqNEUlJSNGPGDE2aNEmNGjVydTklFhQU5OoSAKDcIwChRDw8PCrN2YZGjRpVmrkAAG6MRdAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0ykUAeuuttxQcHCwPDw+1a9dO27dvL7Rvly5dZLFY8m29evWSJF29elXjx49X8+bN5eXlpfr162vw4ME6efLkrZoOAAAo51wegOLj4xUTE6OpU6dq165duueee9SjRw+dPn26wP6ffPKJTp065dj27t0rNzc39e/fX5J06dIl7dq1S5MnT9auXbv0ySef6MCBA+rTp8+tnBYAACjHqri6gNmzZ2v48OEaNmyYJGn+/PlKSEjQwoULNWHChHz9a9eu7fR4+fLlqlatmiMA+fj4aN26dU593nzzTbVt21apqakKCgoqo5kAAICKwqVngHJycrRz505FREQ42qxWqyIiIrR169YijbFgwQI9/PDD8vLyKrRPRkaGLBaLatasWeD+7OxsZWZmOm0AAKDycmkAOnv2rHJzc+Xv7+/U7u/vr7S0tN89fvv27dq7d6+eeOKJQvtcuXJF48eP1yOPPKIaNWoU2Cc2NlY+Pj6OLTAw8OYmAgAAKhSXrwEqiQULFqh58+Zq27ZtgfuvXr2qhx56SIZhaN68eYWOM3HiRGVkZDi2EydOlFXJAACgHHDpGiBfX1+5ubkpPT3dqT09PV316tW74bFZWVlavny5pk+fXuD+vPCTkpKib775ptCzP5Jks9lks9lufgIAAKBCcukZIHd3d4WFhSkxMdHRZrfblZiYqPbt29/w2BUrVig7O1uPPvpovn154efQoUP6+uuvVadOnVKvHQAAVFwuvwssJiZGQ4YMUZs2bdS2bVvNmTNHWVlZjrvCBg8erAYNGig2NtbpuAULFqhv3775ws3Vq1f14IMPateuXfriiy+Um5vrWE9Uu3Ztubu735qJAQCAcsvlASgyMlJnzpzRlClTlJaWppYtW2rNmjWOhdGpqamyWp1PVB04cEDJycn66quv8o33008/adWqVZKkli1bOu1bv369unTpUibzAAAAFYfLA5AkRUVFKSoqqsB9GzZsyNd2xx13yDCMAvsHBwcXug8AAECq4HeBAQAAFAcBCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmE65CEBvvfWWgoOD5eHhoXbt2mn79u2F9u3SpYssFku+rVevXo4+hmFoypQpCggIkKenpyIiInTo0KFbMRUAAFABuDwAxcfHKyYmRlOnTtWuXbt0zz33qEePHjp9+nSB/T/55BOdOnXKse3du1dubm7q37+/o8/LL7+suXPnav78+fr3v/8tLy8v9ejRQ1euXLlV0wIAAOVYFVcXMHv2bA0fPlzDhg2TJM2fP18JCQlauHChJkyYkK9/7dq1nR4vX75c1apVcwQgwzA0Z84c/c///I/+8pe/SJKWLl0qf39/ffrpp3r44YfLeEYAUDlcuXJFqampri4D1wkKCpKHh4ery6gUXBqAcnJytHPnTk2cONHRZrVaFRERoa1btxZpjAULFujhhx+Wl5eXJOnYsWNKS0tTRESEo4+Pj4/atWunrVu3FhiAsrOzlZ2d7XicmZlZ3CkBQKWRmpqqESNGuLoMXCcuLk5NmjRxdRmVgksD0NmzZ5Wbmyt/f3+ndn9/f/3444+/e/z27du1d+9eLViwwNGWlpbmGOO3Y+bt+63Y2FhNmzbtZssHgEotKChIcXFxri6jRFJSUjRjxgxNmjRJjRo1cnU5JRYUFOTqEioNl18CK4kFCxaoefPmatu2bYnGmThxomJiYhyPMzMzFRgYWNLyAKBC8/DwqDRnGxo1alRp5oLS4dJF0L6+vnJzc1N6erpTe3p6uurVq3fDY7OysrR8+XI9/vjjTu15x93MmDabTTVq1HDaAABA5eXSAOTu7q6wsDAlJiY62ux2uxITE9W+ffsbHrtixQplZ2fr0UcfdWoPCQlRvXr1nMbMzMzUv//9798dEwAAmIPLL4HFxMRoyJAhatOmjdq2bas5c+YoKyvLcVfY4MGD1aBBA8XGxjodt2DBAvXt21d16tRxardYLBo7dqxefPFF3X777QoJCdHkyZNVv3599e3b91ZNCwAAlGMuD0CRkZE6c+aMpkyZorS0NLVs2VJr1qxxLGJOTU2V1ep8ourAgQNKTk7WV199VeCYzz33nLKysjRixAidP39e9913n9asWcOtgwAAQFI5CECSFBUVpaioqAL3bdiwIV/bHXfcIcMwCh3PYrFo+vTpmj59emmVCAAAKhGXfxI0AADArUYAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAAplOqAeiXX37R0qVLS3NIAACAUleqASg1NVXDhg0rzSEBAABKXZWb6ZyZmXnD/RcuXChRMQBQWaSnpysjI8PVZZheSkqK03/hWj4+PvL393d1GZJuMgDVrFlTFoul0P2GYdxwPwCYQXp6uh4dNFhXc7JdXQr+vxkzZri6BEiq6m7T++8tLRch6KYCkLe3tyZNmqR27doVuP/QoUN68sknS6UwAKioMjIydDUnW5dv6yy7h4+rywHKBeuVDOnoRmVkZFS8ANS6dWtJUufOnQvcX7NmTRmGUfKqAKASsHv4yO7l6+oyABTgpgLQgAEDdPny5UL316tXT1OnTi1xUWbBGoHygTUC5Ut5WiMAoPK6qQA0fPjwG+739/cnABURawTKH9YIlA/laY0AgMqryAGodu3aOnjwoHx9ffXYY4/p9ddfl7e3d1nWVqmxRgDIr7ytEQBQeRU5AOXk5CgzM1O+vr5asmSJZs2aRQAqBawRAADg1ityAGrfvr369u2rsLAwGYah6OhoeXp6Fth34cKFpVYgAABAaStyAHr//ff1z3/+U0eOHJHFYlFGRoauXLlSlrUBAACUiSIHIH9/f7300kuSpJCQEL333nuqU6dOmRUGAABQVor1XWDHjh0rUvhp3ry5Tpw4UZynAAAAKDOl+mWov3X8+HFdvXq1LJ8CAADgppVpAAIAACiPCEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0yjQAvfPOO3yfDwAAKHeKHYA2btyo3r17KzQ0VKGhoerTp4+SkpKc+gwYMEBeXl4lLhIAAKA0FSsAvf/++4qIiFC1atUUHR3t+F6w+++/X8uWLSvtGgEAAEpVkb8K43ozZszQyy+/rHHjxjnaoqOjNXv2bL3wwgsaMGBAqRUIAABQ2op1Bujo0aPq3bt3vvY+ffro2LFjJS4KAACgLBUrAAUGBioxMTFf+9dff63AwMCbHu+tt95ScHCwPDw81K5dO23fvv2G/c+fP6/Ro0crICBANptNTZo00erVqx37c3NzNXnyZIWEhMjT01ONGzfWCy+8IMMwbro2AABQ+RTrEtjTTz+t6Oho7d69Wx06dJAkbd68WYsXL9brr79+U2PFx8crJiZG8+fPV7t27TRnzhz16NFDBw4cUN26dfP1z8nJUffu3VW3bl2tXLlSDRo0UEpKimrWrOnoM2vWLM2bN09LlizR3XffrW+//VbDhg2Tj4+PoqOjizNlAABQiRQrAI0cOVL16tXTa6+9po8++kiS1LRpU8XHx+svf/nLTY01e/ZsDR8+XMOGDZMkzZ8/XwkJCVq4cKEmTJiQr//ChQt17tw5bdmyRVWrVpUkBQcHO/XZsmWL/vKXv6hXr16O/R9++OHvnlkCAADmcNOXwK5du6bp06fr3nvvVXJysn7++Wf9/PPPSk5Ovunwk5OTo507dyoiIuL/CrJaFRERoa1btxZ4zKpVq9S+fXuNHj1a/v7+atasmWbOnKnc3FxHnw4dOigxMVEHDx6UJO3Zs0fJycnq2bNngWNmZ2crMzPTaQMAAJXXTQegKlWq6OWXX9a1a9dK/ORnz55Vbm5uvg9L9Pf3V1paWoHHHD16VCtXrlRubq5Wr16tyZMn67XXXtOLL77o6DNhwgQ9/PDDuvPOO1W1alW1atVKY8eO1cCBAwscMzY2Vj4+Po6tOOuYAABAxVGsRdD333+/Nm7cWNq1FIndblfdunUVFxensLAwRUZGatKkSZo/f76jz0cffaQPPvhAy5Yt065du7RkyRK9+uqrWrJkSYFjTpw4URkZGY7txIkTt2o6AADABYq1Bqhnz56aMGGCvv/+e4WFheX7tOc+ffoUaRxfX1+5ubkpPT3dqT09PV316tUr8JiAgABVrVpVbm5ujramTZsqLS1NOTk5cnd317PPPus4CyRJzZs3V0pKimJjYzVkyJB8Y9psNtlstiLVDAAAKr5iBaBRo0ZJ+nUB829ZLBan9Tg34u7urrCwMCUmJqpv376Sfj3Dk5iYqKioqAKP6dixo5YtWya73S6r9dcTWAcPHlRAQIDc3d0lSZcuXXLsy+Pm5ia73V6kugAAQOVWrEtgdru90K2o4SdPTEyM3n33XS1ZskQ//PCDRo4cqaysLMddYYMHD9bEiRMd/UeOHKlz585pzJgxOnjwoBISEjRz5kyNHj3a0ad3796aMWOGEhISdPz4cf3rX//S7Nmz1a9fv+JMFwAAVDLFOgNUmiIjI3XmzBlNmTJFaWlpatmypdasWeNYGJ2amup0NicwMFBr167VuHHj1KJFCzVo0EBjxozR+PHjHX3eeOMNTZ48WaNGjdLp06dVv359Pfnkk5oyZcotnx8AACh/ihWAoqOjFRoamu9DBd98800dPnxYc+bMuanxoqKiCr3ktWHDhnxt7du317Zt2wodz9vbW3PmzLnpOgAAgDkU6xLYxx9/rI4dO+Zr79Chg1auXFniogAAAMpSsQLQzz//LB8fn3ztNWrU0NmzZ0tcFAAAQFkqVgAKDQ3VmjVr8rV/+eWXuu2220pcFAAAQFkq1hqgmJgYRUVF6cyZM+rWrZskKTExUa+99hrrbgDg/7NePu/qEoByo7z9PhQrAD322GPKzs7WjBkz9MILL0j69QtH582bp8GDB5dqgQBQUXke2+TqEgAUoti3wY8cOVIjR47UmTNn5OnpqerVq5dmXQBQ4V0O6SS7Z01XlwGUC9bL58vVPwpK/DlAfn5+pVEHAFQ+FourKwDKj3L2+1DsALRy5Up99NFHSk1NVU5OjtO+Xbt2lbgwAKiofHx8VNXdJh11zZdGA+VVVXdbgXeRu0KxAtDcuXM1adIkDR06VJ999pmGDRumI0eOaMeOHU5fSQEAZuTv76/331uqjIwMV5dieikpKZoxY4YmTZqkRo0auboc0/Px8XF804OrFSsAvf3224qLi9MjjzyixYsX67nnntNtt92mKVOm6Ny5c6VdIwBUOP7+/uXmL3pIjRo1UpMmTVxdBsqRYn0OUGpqqjp06CBJ8vT01IULFyRJgwYN0ocfflh61QEAAJSBYgWgevXqOc70BAUFOb6X69ixYzIMo/SqAwAAKAPFCkDdunXTqlWrJEnDhg3TuHHj1L17d0VGRqpfv36lWiAAAEBpK9YaoLi4ONntdknS6NGj5evrq82bN6tPnz76+9//XqoFAgAAlLZiBSCr1aqcnBzt2rVLp0+flqenpyIiIiRJa9asUe/evUu1SAAAgNJUrAC0Zs0aDRo0SD///HO+fRaLRbm5uSUuDADgWleuXFFqaqqryyiRlJQUp/9WdEFBQfLw8HB1GZVCsQLQU089pYceekhTpkzhNk8AqKRSU1M1YsQIV5dRKmbMmOHqEkpFXFwct/OXkmIFoPT0dMXExBB+AKASCwoKUlxcnKvLwHWCgoJcXUKlUawA9OCDD2rDhg1q3LhxadcDACgnPDw8ONuASqtYAejNN99U//79lZSUpObNm6tq1apO+6Ojo0ulOAAAgLJQrAD04Ycf6quvvpKHh4c2bNggy3Xf8GqxWAhAAACgXCtWAJo0aZKmTZumCRMmyGot1mcpAgAAuEyx0ktOTo4iIyMJPwAAoEIqVoIZMmSI4uPjS7sWAACAW6JYl8Byc3P18ssva+3atWrRokW+RdCzZ88uleIAAADKQrEC0Pfff69WrVpJkvbu3eu07/oF0QAAAOVRsQLQ+vXrS7sOAACAW4ZVzAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHTKRQB66623FBwcLA8PD7Vr107bt2+/Yf/z589r9OjRCggIkM1mU5MmTbR69WqnPj/99JMeffRR1alTR56enmrevLm+/fbbspwGAACoIKq4uoD4+HjFxMRo/vz5ateunebMmaMePXrowIEDqlu3br7+OTk56t69u+rWrauVK1eqQYMGSklJUc2aNR19fvnlF3Xs2FFdu3bVl19+KT8/Px06dEi1atW6hTMDAADllcsD0OzZszV8+HANGzZMkjR//nwlJCRo4cKFmjBhQr7+Cxcu1Llz57RlyxZVrVpVkhQcHOzUZ9asWQoMDNSiRYscbSEhIWU3CQAAUKG49BJYTk6Odu7cqYiICEeb1WpVRESEtm7dWuAxq1atUvv27TV69Gj5+/urWbNmmjlzpnJzc536tGnTRv3791fdunXVqlUrvfvuu4XWkZ2drczMTKcNAABUXi4NQGfPnlVubq78/f2d2v39/ZWWllbgMUePHtXKlSuVm5ur1atXa/LkyXrttdf04osvOvWZN2+ebr/9dq1du1YjR45UdHS0lixZUuCYsbGx8vHxcWyBgYGlN0kAAFDuuPwS2M2y2+2qW7eu4uLi5ObmprCwMP3000965ZVXNHXqVEefNm3aaObMmZKkVq1aae/evZo/f76GDBmSb8yJEycqJibG8TgzM5MQBABAJebSAOTr6ys3Nzelp6c7taenp6tevXoFHhMQEKCqVavKzc3N0da0aVOlpaUpJydH7u7uCggI0F133eV0XNOmTfXxxx8XOKbNZpPNZivhbAAAQEXh0ktg7u7uCgsLU2JioqPNbrcrMTFR7du3L/CYjh076vDhw7Lb7Y62gwcPKiAgQO7u7o4+Bw4ccDru4MGDatSoURnMAgAAVDQu/xygmJgYvfvuu1qyZIl++OEHjRw5UllZWY67wgYPHqyJEyc6+o8cOVLnzp3TmDFjdPDgQSUkJGjmzJkaPXq0o8+4ceO0bds2zZw5U4cPH9ayZcsUFxfn1AcAAJiXy9cARUZG6syZM5oyZYrS0tLUsmVLrVmzxrEwOjU1VVbr/+W0wMBArV27VuPGjVOLFi3UoEEDjRkzRuPHj3f0uffee/Wvf/1LEydO1PTp0xUSEqI5c+Zo4MCBt3x+AACg/LEYhmG4uojyJjMzUz4+PsrIyFCNGjXK5DkOHjyoESNGKOuuPrJ7+ZbJcwAVjTXrrLz2r1JcXJyaNGni6nIAVDA38/7t8ktgAAAAtxoBCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmE4VVxdgdtbL511dAlBu8PsA4FYhALmY57FNri4BAADTIQC52OWQTrJ71nR1GUC5YL18nn8UALglCEAuZvesKbuXr6vLAADAVFgEDQAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATIcABAAATKdcBKC33npLwcHB8vDwULt27bR9+/Yb9j9//rxGjx6tgIAA2Ww2NWnSRKtXry6w70svvSSLxaKxY8eWQeUAAKAiquLqAuLj4xUTE6P58+erXbt2mjNnjnr06KEDBw6obt26+frn5OSoe/fuqlu3rlauXKkGDRooJSVFNWvWzNd3x44deuedd9SiRYtbMBMAAFBRuPwM0OzZszV8+HANGzZMd911l+bPn69q1app4cKFBfZfuHChzp07p08//VQdO3ZUcHCwOnfurHvuucep38WLFzVw4EC9++67qlWr1q2YCgAAqCBcGoBycnK0c+dORUREONqsVqsiIiK0devWAo9ZtWqV2rdvr9GjR8vf31/NmjXTzJkzlZub69Rv9OjR6tWrl9PYAAAAkosvgZ09e1a5ubny9/d3avf399ePP/5Y4DFHjx7VN998o4EDB2r16tU6fPiwRo0apatXr2rq1KmSpOXLl2vXrl3asWNHkerIzs5Wdna243FmZmYxZwQAACoCl68Bull2u11169ZVXFyc3NzcFBYWpp9++kmvvPKKpk6dqhMnTmjMmDFat26dPDw8ijRmbGyspk2bVsaVAwCA8sKll8B8fX3l5uam9PR0p/b09HTVq1evwGMCAgLUpEkTubm5OdqaNm2qtLQ0xyW106dPq3Xr1qpSpYqqVKmijRs3au7cuapSpUq+S2WSNHHiRGVkZDi2EydOlO5EAQBAueLSAOTu7q6wsDAlJiY62ux2uxITE9W+ffsCj+nYsaMOHz4su93uaDt48KACAgLk7u6u+++/X99//712797t2Nq0aaOBAwdq9+7dTsEpj81mU40aNZw2AABQebn8ElhMTIyGDBmiNm3aqG3btpozZ46ysrI0bNgwSdLgwYPVoEEDxcbGSpJGjhypN998U2PGjNFTTz2lQ4cOaebMmYqOjpYkeXt7q1mzZk7P4eXlpTp16uRrBwAA5uTyABQZGakzZ85oypQpSktLU8uWLbVmzRrHwujU1FRZrf93oiowMFBr167VuHHj1KJFCzVo0EBjxozR+PHjXTUFAABQwbg8AElSVFSUoqKiCty3YcOGfG3t27fXtm3bijx+QWMAAADzcvkHIQIAANxqBCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6BCAAAGA6VVxdgNlZr2S4uoSSsV+TNfuiq6vAdey26pK1Yv5qV/jfBwAVRsX8W7IS8PHxUVV3m3R0o6tLAcqVqu42+fj4uLoMAJUcAchF/P399f57S5WRUbH/xZudna20tDRXl4Hr1KtXTzabzdVlFJuPj4/8/f1dXQaASo4A5EL+/v6V4i/65s2bu7oEAABuCougAQCA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6fBt8AUwDEOSlJmZ6eJKAABAUeW9b+e9j98IAagAFy5ckCQFBga6uBIAAHCzLly4IB8fnxv2sRhFiUkmY7fbdfLkSXl7e8tisbi6HJSxzMxMBQYG6sSJE6pRo4arywFQivj9NhfDMHThwgXVr19fVuuNV/lwBqgAVqtVDRs2dHUZuMVq1KjBX5BAJcXvt3n83pmfPCyCBgAApkMAAgAApkMAgunZbDZNnTpVNpvN1aUAKGX8fqMwLIIGAACmwxkgAABgOgQgAABgOgQgAABgOgQgmNrixYtVs2ZNV5cBALjFCECoFIYOHSqLxZJvO3z4sKtLA1BKCvodv357/vnnXV0iKhA+CRqVxgMPPKBFixY5tfn5+bmoGgCl7dSpU47/j4+P15QpU3TgwAFHW/Xq1R3/bxiGcnNzVaUKb3MoGGeAUGnYbDbVq1fPaXv99dfVvHlzeXl5KTAwUKNGjdLFixcLHWPPnj3q2rWrvL29VaNGDYWFhenbb7917E9OTlZ4eLg8PT0VGBio6OhoZWVl3YrpAaZ3/e+2j4+PLBaL4/GPP/4ob29vffnllwoLC5PNZlNycrKGDh2qvn37Oo0zduxYdenSxfHYbrcrNjZWISEh8vT01D333KOVK1fe2snhliMAoVKzWq2aO3eu9u3bpyVLluibb77Rc889V2j/gQMHqmHDhtqxY4d27typCRMmqGrVqpKkI0eO6IEHHtDf/vY3fffdd4qPj1dycrKioqJu1XQA/I4JEybopZde0g8//KAWLVoU6ZjY2FgtXbpU8+fP1759+zRu3Dg9+uij2rhxYxlXC1fi3CAqjS+++MLpFHjPnj21YsUKx+Pg4GC9+OKL+vvf/6633367wDFSU1P17LPP6s4775Qk3X777Y59sbGxGjhwoMaOHevYN3fuXHXu3Fnz5s2Th4dHGcwKwM2YPn26unfvXuT+2dnZmjlzpr7++mu1b99eknTbbbcpOTlZ77zzjjp37lxWpcLFCECoNLp27ap58+Y5Hnt5eenrr79WbGysfvzxR2VmZuratWu6cuWKLl26pGrVquUbIyYmRk888YTee+89RUREqH///mrcuLGkXy+Pfffdd/rggw8c/Q3DkN1u17Fjx9S0adOynySAG2rTps1N9T98+LAuXbqULzTl5OSoVatWpVkayhkCECoNLy8vhYaGOh4fP35cf/7znzVy5EjNmDFDtWvXVnJysh5//HHl5OQUGICef/55DRgwQAkJCfryyy81depULV++XP369dPFixf15JNPKjo6Ot9xQUFBZTo3AEXj5eXl9Nhqteq33/h09epVx//nrQlMSEhQgwYNnPrx/WGVGwEIldbOnTtlt9v12muvyWr9dbnbRx999LvHNWnSRE2aNNG4ceP0yCOPaNGiRerXr59at26t/fv3O4UsAOWbn5+f9u7d69S2e/dux9q+u+66SzabTampqVzuMhkWQaPSCg0N1dWrV/XGG2/o6NGjeu+99zR//vxC+1++fFlRUVHasGGDUlJStHnzZu3YscNxaWv8+PHasmWLoqKitHv3bh06dEifffYZi6CBcqxbt2769ttvtXTpUh06dEhTp051CkTe3t565plnNG7cOC1ZskRHjhzRrl279MYbb2jJkiUurBxljQCESuuee+7R7NmzNWvWLDVr1kwffPCBYmNjC+3v5uamn3/+WYMHD1aTJk300EMPqWfPnpo2bZokqUWLFtq4caMOHjyo8PBwtWrVSlOmTFH9+vVv1ZQA3KQePXpo8uTJeu6553TvvffqwoULGjx4sFOfF154QZMnT1ZsbKyaNm2qBx54QAkJCQoJCXFR1bgVLMZvL44CAABUcpwBAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAgAApkMAAmA6wcHBmjNnToUZF0DpIwABAADTIQABKHfsdrtefvllhYaGymazKSgoSDNmzJAkff/99+rWrZs8PT1Vp04djRgxQhcvXnQcO3ToUPXt21evvvqqAgICVKdOHY0ePVpXr16VJHXp0kUpKSkaN26cLBaLLBaL49jk5GSFh4fL09NTgYGBio6OVlZWliRp6dKlql69ug4dOuToP2rUKN155526dOnSDccFUP4QgACUOxMnTtRLL72kyZMna//+/Vq2bJn8/f2VlZWlHj16qFatWtqxY4dWrFihr7/+WlFRUU7Hr1+/XkeOHNH69eu1ZMkSLV68WIsXL5YkffLJJ2rYsKGmT5+uU6dO6dSpU5KkI0eO6IEHHtDf/vY3fffdd4qPj1dycrJj7MGDB+tPf/qTBg4cqGvXrikhIUH/+7//qw8++EDVqlUrdFwA5ZQBAOVIZmamYbPZjHfffTffvri4OKNWrVrGxYsXHW0JCQmG1Wo10tLSDMMwjCFDhhiNGjUyrl275ujTv39/IzIy0vG4UaNGxj//+U+nsR9//HFjxIgRTm1JSUmG1Wo1Ll++bBiGYZw7d85o2LChMXLkSMPf39+YMWOGU/+CxgVQPnEGCEC58sMPPyg7O1v3339/gfvuueceeXl5Odo6duwou92uAwcOONruvvtuubm5OR4HBATo9OnTN3zePXv2aPHixapevbpj69Gjh+x2u44dOyZJqlWrlhYsWKB58+apcePGmjBhQkmnC8BFqri6AAC4nqenZ4nHqFq1qtNji8Uiu91+w2MuXryoJ598UtHR0fn2BQUFOf5/06ZNcnNz06lTp5SVlSVvb+8S1wvg1uMMEIBy5fbbb5enp6cSExPz7WvatKn27NnjWJgsSZs3b5bVatUdd9xR5Odwd3dXbm6uU1vr1q21f/9+hYaG5tvc3d0lSVu2bNGsWbP0+eefq3r16vnWHhU0LoDyiQAEoFzx8PDQ+PHj9dxzz2np0qU6cuSItm3bpgULFmjgwIHy8PDQkCFDtHfvXq1fv15PPfWUBg0aJH9//yI/R3BwsDZt2qSffvpJZ8+elSSNHz9eW7ZsUVRUlHbv3q1Dhw7ps88+c4ScCxcuaNCgQYqOjlbPnj31wQcfKD4+XitXrrzhuADKJwIQgHJn8uTJevrppzVlyhQ1bdpUkZGROn36tKpVq6a1a9fq3Llzuvfee/Xggw/q/vvv15tvvnlT40+fPl3Hjx9X48aN5efnJ0lq0aKFNm7cqIMHDyo8PFytWrXSlClTVL9+fUnSmDFj5OXlpZkzZ0qSmjdvrpkzZ+rJJ5/UTz/9VOi4AMoni2EYhquLAAAAuJU4AwQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEyHAAQAAEzn/wGTTzFJp+/1dQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_context = pd.read_csv(\"results_context_comparison.csv\")\n",
    "sns.boxplot(data=df_context, x=\"context\", y=\"macro_f1\")\n",
    "plt.title(\"Macro F1 without vs with context\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e655a2-c4bd-4e76-99bc-682abb52bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roberta large performs better with context, across all metrics and seeds. E un outlier in care pt no context am obt 0.73."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5901a5c1-7a1e-49cc-8870-f8260665f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = alpha_equal\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "999c21ff-08bd-4244-9644-823f0b1c6f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9176, 1.9058, 0.1766])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights_normalized\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da911e-7ced-439b-991c-9f2af8952ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "*Din punctul asta am folosit balanced_accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "755657a2-1e92-4f6c-8491-fcddc6892062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Running: loss_type=weighted, seed=42 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.956100</td>\n",
       "      <td>0.863100</td>\n",
       "      <td>0.599328</td>\n",
       "      <td>0.611783</td>\n",
       "      <td>0.745385</td>\n",
       "      <td>0.956621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.853500</td>\n",
       "      <td>0.812704</td>\n",
       "      <td>0.655930</td>\n",
       "      <td>0.670476</td>\n",
       "      <td>0.821037</td>\n",
       "      <td>0.951479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>1.086142</td>\n",
       "      <td>0.610736</td>\n",
       "      <td>0.639130</td>\n",
       "      <td>0.822228</td>\n",
       "      <td>0.952719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>1.097463</td>\n",
       "      <td>0.622627</td>\n",
       "      <td>0.643561</td>\n",
       "      <td>0.830267</td>\n",
       "      <td>0.955083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 36  12  25]\n",
      " [  1  12  18]\n",
      " [  0  32 357]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.97      0.49      0.65        73\n",
      "         TSE       0.21      0.39      0.28        31\n",
      "         Yes       0.89      0.92      0.90       389\n",
      "\n",
      "    accuracy                           0.82       493\n",
      "   macro avg       0.69      0.60      0.61       493\n",
      "weighted avg       0.86      0.82      0.83       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   3  20]\n",
      " [  2  11  18]\n",
      " [ 16  12 361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.74      0.68      0.71        73\n",
      "         TSE       0.42      0.35      0.39        31\n",
      "         Yes       0.90      0.93      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.69      0.66      0.67       493\n",
      "weighted avg       0.85      0.86      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1  22]\n",
      " [  4   6  21]\n",
      " [ 13   5 371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.75      0.68      0.71        73\n",
      "         TSE       0.50      0.19      0.28        31\n",
      "         Yes       0.90      0.95      0.92       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.71      0.61      0.64       493\n",
      "weighted avg       0.85      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  4   7  20]\n",
      " [ 12  10 367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.76      0.70      0.73        73\n",
      "         TSE       0.37      0.23      0.28        31\n",
      "         Yes       0.90      0.94      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.68      0.62      0.64       493\n",
      "weighted avg       0.85      0.86      0.85       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 50   3  20]\n",
      " [  2  11  18]\n",
      " [ 16  12 361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.74      0.68      0.71        73\n",
      "         TSE       0.42      0.35      0.39        31\n",
      "         Yes       0.90      0.93      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.69      0.66      0.67       493\n",
      "weighted avg       0.85      0.86      0.85       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=weighted, seed=52 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.992200</td>\n",
       "      <td>1.009137</td>\n",
       "      <td>0.487043</td>\n",
       "      <td>0.248118</td>\n",
       "      <td>0.791895</td>\n",
       "      <td>0.879487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.917700</td>\n",
       "      <td>0.790177</td>\n",
       "      <td>0.648218</td>\n",
       "      <td>0.649780</td>\n",
       "      <td>0.831751</td>\n",
       "      <td>0.962529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>1.020149</td>\n",
       "      <td>0.643181</td>\n",
       "      <td>0.673490</td>\n",
       "      <td>0.853196</td>\n",
       "      <td>0.960947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>1.159253</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>0.674565</td>\n",
       "      <td>0.852299</td>\n",
       "      <td>0.965922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 56  17   0]\n",
      " [ 11  20   0]\n",
      " [ 66 304  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.42      0.77      0.54        73\n",
      "         TSE       0.06      0.65      0.11        31\n",
      "         Yes       1.00      0.05      0.09       389\n",
      "\n",
      "    accuracy                           0.19       493\n",
      "   macro avg       0.49      0.49      0.25       493\n",
      "weighted avg       0.86      0.19      0.16       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   6  17]\n",
      " [  1  11  19]\n",
      " [  8  29 352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.68      0.76        73\n",
      "         TSE       0.24      0.35      0.29        31\n",
      "         Yes       0.91      0.90      0.91       389\n",
      "\n",
      "    accuracy                           0.84       493\n",
      "   macro avg       0.66      0.65      0.65       493\n",
      "weighted avg       0.86      0.84      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   2  17]\n",
      " [  4   7  20]\n",
      " [ 10   4 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.74      0.77        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.91      0.96      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.64      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  2   7  22]\n",
      " [  7   6 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.73      0.79        73\n",
      "         TSE       0.47      0.23      0.30        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.64      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  2   7  22]\n",
      " [  7   6 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.73      0.79        73\n",
      "         TSE       0.47      0.23      0.30        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.64      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=weighted, seed=62 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.966300</td>\n",
       "      <td>0.862820</td>\n",
       "      <td>0.573623</td>\n",
       "      <td>0.443360</td>\n",
       "      <td>0.784736</td>\n",
       "      <td>0.898876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.879300</td>\n",
       "      <td>0.794252</td>\n",
       "      <td>0.631091</td>\n",
       "      <td>0.639261</td>\n",
       "      <td>0.834736</td>\n",
       "      <td>0.953737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.618200</td>\n",
       "      <td>0.968951</td>\n",
       "      <td>0.630139</td>\n",
       "      <td>0.646597</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.950898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.554200</td>\n",
       "      <td>1.062273</td>\n",
       "      <td>0.669241</td>\n",
       "      <td>0.672352</td>\n",
       "      <td>0.865117</td>\n",
       "      <td>0.949275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   7  14]\n",
      " [  6  17   8]\n",
      " [ 54 156 179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.46      0.71      0.56        73\n",
      "         TSE       0.09      0.55      0.16        31\n",
      "         Yes       0.89      0.46      0.61       389\n",
      "\n",
      "    accuracy                           0.50       493\n",
      "   macro avg       0.48      0.57      0.44       493\n",
      "weighted avg       0.78      0.50      0.57       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  5   8  18]\n",
      " [ 13  17 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.74      0.71      0.73        73\n",
      "         TSE       0.30      0.26      0.28        31\n",
      "         Yes       0.91      0.92      0.91       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.65      0.63      0.64       493\n",
      "weighted avg       0.84      0.85      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 55   1  17]\n",
      " [  5   6  20]\n",
      " [ 18   4 367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.71      0.75      0.73        73\n",
      "         TSE       0.55      0.19      0.29        31\n",
      "         Yes       0.91      0.94      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.63      0.65       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58   1  14]\n",
      " [  6   9  16]\n",
      " [ 21   9 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.79      0.73        73\n",
      "         TSE       0.47      0.29      0.36        31\n",
      "         Yes       0.92      0.92      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.69      0.67      0.67       493\n",
      "weighted avg       0.86      0.86      0.86       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 58   1  14]\n",
      " [  6   9  16]\n",
      " [ 21   9 359]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.79      0.73        73\n",
      "         TSE       0.47      0.29      0.36        31\n",
      "         Yes       0.92      0.92      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.69      0.67      0.67       493\n",
      "weighted avg       0.86      0.86      0.86       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=weighted, seed=88 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.038100</td>\n",
       "      <td>0.872271</td>\n",
       "      <td>0.633761</td>\n",
       "      <td>0.480495</td>\n",
       "      <td>0.807942</td>\n",
       "      <td>0.937650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>0.844411</td>\n",
       "      <td>0.662785</td>\n",
       "      <td>0.689547</td>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.963743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.956117</td>\n",
       "      <td>0.630621</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>0.839498</td>\n",
       "      <td>0.958678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>1.159820</td>\n",
       "      <td>0.654215</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.861236</td>\n",
       "      <td>0.963314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 50  12  11]\n",
      " [  4  24   3]\n",
      " [ 25 192 172]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.63      0.68      0.66        73\n",
      "         TSE       0.11      0.77      0.19        31\n",
      "         Yes       0.92      0.44      0.60       389\n",
      "\n",
      "    accuracy                           0.50       493\n",
      "   macro avg       0.55      0.63      0.48       493\n",
      "weighted avg       0.83      0.50      0.58       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   3  20]\n",
      " [  1  11  19]\n",
      " [  7  13 369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.68      0.76        73\n",
      "         TSE       0.41      0.35      0.38        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.66      0.69       493\n",
      "weighted avg       0.87      0.87      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  2   7  22]\n",
      " [ 12   6 371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.71      0.75        73\n",
      "         TSE       0.47      0.23      0.30        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.63      0.66       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 55   2  16]\n",
      " [  2   8  21]\n",
      " [ 11   8 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.75      0.78        73\n",
      "         TSE       0.44      0.26      0.33        31\n",
      "         Yes       0.91      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.72      0.65      0.68       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 50   3  20]\n",
      " [  1  11  19]\n",
      " [  7  13 369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.68      0.76        73\n",
      "         TSE       0.41      0.35      0.38        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.66      0.69       493\n",
      "weighted avg       0.87      0.87      0.87       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=weighted, seed=99 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.893195</td>\n",
       "      <td>0.532919</td>\n",
       "      <td>0.315224</td>\n",
       "      <td>0.817759</td>\n",
       "      <td>0.954064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858200</td>\n",
       "      <td>0.846857</td>\n",
       "      <td>0.689609</td>\n",
       "      <td>0.679166</td>\n",
       "      <td>0.835926</td>\n",
       "      <td>0.954976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.637200</td>\n",
       "      <td>1.006604</td>\n",
       "      <td>0.612261</td>\n",
       "      <td>0.649052</td>\n",
       "      <td>0.837410</td>\n",
       "      <td>0.962441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>1.137059</td>\n",
       "      <td>0.645846</td>\n",
       "      <td>0.673262</td>\n",
       "      <td>0.831458</td>\n",
       "      <td>0.956316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 49  24   0]\n",
      " [  4  27   0]\n",
      " [ 11 356  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.77      0.67      0.72        73\n",
      "         TSE       0.07      0.87      0.12        31\n",
      "         Yes       1.00      0.06      0.11       389\n",
      "\n",
      "    accuracy                           0.20       493\n",
      "   macro avg       0.61      0.53      0.32       493\n",
      "weighted avg       0.91      0.20      0.20       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   4  17]\n",
      " [  2  14  15]\n",
      " [ 15  22 352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.75      0.71      0.73        73\n",
      "         TSE       0.35      0.45      0.39        31\n",
      "         Yes       0.92      0.90      0.91       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.67      0.69      0.68       493\n",
      "weighted avg       0.86      0.85      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  3   5  23]\n",
      " [  7   2 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.70      0.76        73\n",
      "         TSE       0.56      0.16      0.25        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.76      0.61      0.65       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  3   9  19]\n",
      " [ 12   8 369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.77      0.70      0.73        73\n",
      "         TSE       0.47      0.29      0.36        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.65      0.67       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   4  17]\n",
      " [  2  14  15]\n",
      " [ 15  22 352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.75      0.71      0.73        73\n",
      "         TSE       0.35      0.45      0.39        31\n",
      "         Yes       0.92      0.90      0.91       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.67      0.69      0.68       493\n",
      "weighted avg       0.86      0.85      0.85       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=focal, seed=42 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.171431</td>\n",
       "      <td>0.557654</td>\n",
       "      <td>0.601749</td>\n",
       "      <td>0.789759</td>\n",
       "      <td>0.960739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.228092</td>\n",
       "      <td>0.558511</td>\n",
       "      <td>0.600953</td>\n",
       "      <td>0.788568</td>\n",
       "      <td>0.959538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.214397</td>\n",
       "      <td>0.599888</td>\n",
       "      <td>0.623948</td>\n",
       "      <td>0.849918</td>\n",
       "      <td>0.963486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.241446</td>\n",
       "      <td>0.644519</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.839791</td>\n",
       "      <td>0.964871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 43   1  29]\n",
      " [  1   3  27]\n",
      " [  3   2 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.59      0.72        73\n",
      "         TSE       0.50      0.10      0.16        31\n",
      "         Yes       0.87      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.76      0.56      0.60       493\n",
      "weighted avg       0.86      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 43   2  28]\n",
      " [  2   3  26]\n",
      " [  3   1 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.59      0.71        73\n",
      "         TSE       0.50      0.10      0.16        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.76      0.56      0.60       493\n",
      "weighted avg       0.86      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  4   3  24]\n",
      " [  7   2 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.73      0.77        73\n",
      "         TSE       0.50      0.10      0.16        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.60      0.62       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  2   8  21]\n",
      " [  6   3 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.70      0.77        73\n",
      "         TSE       0.62      0.26      0.36        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.64      0.69       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  2   8  21]\n",
      " [  6   3 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.70      0.77        73\n",
      "         TSE       0.62      0.26      0.36        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.64      0.69       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=focal, seed=52 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>0.174165</td>\n",
       "      <td>0.563452</td>\n",
       "      <td>0.593193</td>\n",
       "      <td>0.813584</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.578302</td>\n",
       "      <td>0.632976</td>\n",
       "      <td>0.790949</td>\n",
       "      <td>0.961938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.245319</td>\n",
       "      <td>0.612637</td>\n",
       "      <td>0.637264</td>\n",
       "      <td>0.850815</td>\n",
       "      <td>0.958482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.246164</td>\n",
       "      <td>0.636619</td>\n",
       "      <td>0.675118</td>\n",
       "      <td>0.844260</td>\n",
       "      <td>0.963572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 47   1  25]\n",
      " [  2   2  27]\n",
      " [  5   2 382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.64      0.74        73\n",
      "         TSE       0.40      0.06      0.11        31\n",
      "         Yes       0.88      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.56      0.59       493\n",
      "weighted avg       0.85      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 43   1  29]\n",
      " [  0   5  26]\n",
      " [  3   3 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.59      0.72        73\n",
      "         TSE       0.56      0.16      0.25        31\n",
      "         Yes       0.87      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.79      0.58      0.63       493\n",
      "weighted avg       0.86      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   0  19]\n",
      " [  5   4  22]\n",
      " [ 11   1 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.77      0.74      0.76        73\n",
      "         TSE       0.80      0.13      0.22        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.82      0.61      0.64       493\n",
      "weighted avg       0.88      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   7  21]\n",
      " [  7   4 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.76      0.64      0.68       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   7  21]\n",
      " [  7   4 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.76      0.64      0.68       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=focal, seed=62 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.182241</td>\n",
       "      <td>0.531958</td>\n",
       "      <td>0.543377</td>\n",
       "      <td>0.796314</td>\n",
       "      <td>0.955711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.205485</td>\n",
       "      <td>0.594947</td>\n",
       "      <td>0.638638</td>\n",
       "      <td>0.830855</td>\n",
       "      <td>0.967442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.600652</td>\n",
       "      <td>0.634325</td>\n",
       "      <td>0.836220</td>\n",
       "      <td>0.961222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106200</td>\n",
       "      <td>0.255305</td>\n",
       "      <td>0.650224</td>\n",
       "      <td>0.689710</td>\n",
       "      <td>0.851109</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 45   3  25]\n",
      " [  4   0  27]\n",
      " [  6   2 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.62      0.70        73\n",
      "         TSE       0.00      0.00      0.00        31\n",
      "         Yes       0.88      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.57      0.53      0.54       493\n",
      "weighted avg       0.82      0.86      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49   1  23]\n",
      " [  1   4  26]\n",
      " [  3   3 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.67      0.78        73\n",
      "         TSE       0.50      0.13      0.21        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.77      0.59      0.64       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   0  22]\n",
      " [  3   4  24]\n",
      " [  8   2 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.70      0.76        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.79      0.60      0.63       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   8  21]\n",
      " [  8   5 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.73      0.78        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.77      0.65      0.69       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   8  21]\n",
      " [  8   5 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.73      0.78        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.77      0.65      0.69       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=focal, seed=88 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.213068</td>\n",
       "      <td>0.591039</td>\n",
       "      <td>0.605436</td>\n",
       "      <td>0.792156</td>\n",
       "      <td>0.939358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.227770</td>\n",
       "      <td>0.627593</td>\n",
       "      <td>0.686596</td>\n",
       "      <td>0.800179</td>\n",
       "      <td>0.965438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.228539</td>\n",
       "      <td>0.606838</td>\n",
       "      <td>0.643255</td>\n",
       "      <td>0.829371</td>\n",
       "      <td>0.960094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.650224</td>\n",
       "      <td>0.685267</td>\n",
       "      <td>0.847538</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 47   3  23]\n",
      " [  8   6  17]\n",
      " [ 17   8 364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.65      0.64      0.65        73\n",
      "         TSE       0.35      0.19      0.25        31\n",
      "         Yes       0.90      0.94      0.92       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.64      0.59      0.61       493\n",
      "weighted avg       0.83      0.85      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 44   4  25]\n",
      " [  1   9  21]\n",
      " [  0   4 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.98      0.60      0.75        73\n",
      "         TSE       0.53      0.29      0.38        31\n",
      "         Yes       0.89      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.80      0.63      0.69       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   2  21]\n",
      " [  3   5  23]\n",
      " [  8   2 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.68      0.75        73\n",
      "         TSE       0.56      0.16      0.25        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.76      0.61      0.64       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   3  17]\n",
      " [  3   8  20]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.73      0.76        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.76      0.65      0.69       493\n",
      "weighted avg       0.87      0.89      0.88       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 44   4  25]\n",
      " [  1   9  21]\n",
      " [  0   4 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.98      0.60      0.75        73\n",
      "         TSE       0.53      0.29      0.38        31\n",
      "         Yes       0.89      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.80      0.63      0.69       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "\n",
      "==== Running: loss_type=focal, seed=99 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.186963</td>\n",
       "      <td>0.528823</td>\n",
       "      <td>0.553686</td>\n",
       "      <td>0.793330</td>\n",
       "      <td>0.964327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.228318</td>\n",
       "      <td>0.620832</td>\n",
       "      <td>0.672118</td>\n",
       "      <td>0.811497</td>\n",
       "      <td>0.965278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.236786</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.648902</td>\n",
       "      <td>0.843966</td>\n",
       "      <td>0.957346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.243520</td>\n",
       "      <td>0.655554</td>\n",
       "      <td>0.693894</td>\n",
       "      <td>0.843069</td>\n",
       "      <td>0.962353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 43   0  30]\n",
      " [  0   0  31]\n",
      " [  1   0 388]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.98      0.59      0.74        73\n",
      "         TSE       0.00      0.00      0.00        31\n",
      "         Yes       0.86      1.00      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.61      0.53      0.55       493\n",
      "weighted avg       0.83      0.87      0.84       493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 46   2  25]\n",
      " [  0   8  23]\n",
      " [  3   7 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.63      0.75        73\n",
      "         TSE       0.47      0.26      0.33        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.77      0.62      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  3   6  22]\n",
      " [ 13   5 371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.77      0.73      0.75        73\n",
      "         TSE       0.46      0.19      0.27        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.71      0.62      0.65       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  2   9  20]\n",
      " [  9   5 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.71      0.76        73\n",
      "         TSE       0.56      0.29      0.38        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.76      0.66      0.69       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  2   9  20]\n",
      " [  9   5 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.71      0.76        73\n",
      "         TSE       0.56      0.29      0.38        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.76      0.66      0.69       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, random\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "seeds = [42, 52, 62, 88, 99]\n",
    "loss_types = [\"weighted\", \"focal\"]\n",
    "\n",
    "for loss_type in loss_types:\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n==== Running: loss_type={loss_type}, seed={seed} ====\")\n",
    "\n",
    "        # Fix seed\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        # Define trainer\n",
    "        model = RobertaForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n",
    "\n",
    "        trainer = CustomTrainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=train_ds_context, # ALWAYS USING CONTEXT FROM NOW ON\n",
    "            eval_dataset=val_ds_context,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "            loss_type=loss_type\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "        \"loss_type\": loss_type,\n",
    "        \"seed\": seed,\n",
    "        \"loss\": metrics.get(\"eval_loss\", -1),\n",
    "        \"macro_f1\": metrics.get(\"eval_macro_f1\", -1),\n",
    "        \"lenient_f1\": metrics.get(\"eval_lenient_f1\", -1),\n",
    "        \"accuracy\": metrics.get(\"eval_accuracy\", -1),\n",
    "        \"lenient_accuracy\": metrics.get(\"eval_lenient_accuracy\", -1)\n",
    "      })\n",
    "\n",
    "\n",
    "# Create result DataFrame\n",
    "df_loss = pd.DataFrame(results)\n",
    "df_loss.to_csv(\"results_loss_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b46b8a2-14a8-4014-8207-ebdd598425c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>loss</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>lenient_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lenient_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted</td>\n",
       "      <td>42</td>\n",
       "      <td>0.812704</td>\n",
       "      <td>0.670476</td>\n",
       "      <td>0.951479</td>\n",
       "      <td>0.655930</td>\n",
       "      <td>0.821037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted</td>\n",
       "      <td>52</td>\n",
       "      <td>1.159253</td>\n",
       "      <td>0.674565</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>0.852299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted</td>\n",
       "      <td>62</td>\n",
       "      <td>1.062273</td>\n",
       "      <td>0.672352</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.669241</td>\n",
       "      <td>0.865117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted</td>\n",
       "      <td>88</td>\n",
       "      <td>0.844411</td>\n",
       "      <td>0.689547</td>\n",
       "      <td>0.963743</td>\n",
       "      <td>0.662785</td>\n",
       "      <td>0.832942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted</td>\n",
       "      <td>99</td>\n",
       "      <td>0.846857</td>\n",
       "      <td>0.679166</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.689609</td>\n",
       "      <td>0.835926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>focal</td>\n",
       "      <td>42</td>\n",
       "      <td>0.241446</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.644519</td>\n",
       "      <td>0.839791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>focal</td>\n",
       "      <td>52</td>\n",
       "      <td>0.246164</td>\n",
       "      <td>0.675118</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.636619</td>\n",
       "      <td>0.844260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>focal</td>\n",
       "      <td>62</td>\n",
       "      <td>0.255305</td>\n",
       "      <td>0.689710</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.650224</td>\n",
       "      <td>0.851109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>focal</td>\n",
       "      <td>88</td>\n",
       "      <td>0.227770</td>\n",
       "      <td>0.686596</td>\n",
       "      <td>0.965438</td>\n",
       "      <td>0.627593</td>\n",
       "      <td>0.800179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>focal</td>\n",
       "      <td>99</td>\n",
       "      <td>0.243520</td>\n",
       "      <td>0.693894</td>\n",
       "      <td>0.962353</td>\n",
       "      <td>0.655554</td>\n",
       "      <td>0.843069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loss_type  seed      loss  macro_f1  lenient_f1  accuracy  lenient_accuracy\n",
       "0  weighted    42  0.812704  0.670476    0.951479  0.655930          0.821037\n",
       "1  weighted    52  1.159253  0.674565    0.965922  0.639472          0.852299\n",
       "2  weighted    62  1.062273  0.672352    0.949275  0.669241          0.865117\n",
       "3  weighted    88  0.844411  0.689547    0.963743  0.662785          0.832942\n",
       "4  weighted    99  0.846857  0.679166    0.954976  0.689609          0.835926\n",
       "5     focal    42  0.241446  0.691545    0.964871  0.644519          0.839791\n",
       "6     focal    52  0.246164  0.675118    0.963572  0.636619          0.844260\n",
       "7     focal    62  0.255305  0.689710    0.964706  0.650224          0.851109\n",
       "8     focal    88  0.227770  0.686596    0.965438  0.627593          0.800179\n",
       "9     focal    99  0.243520  0.693894    0.962353  0.655554          0.843069"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b77a90-49c6-4c2c-9bf9-da9e4bd6dac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>loss</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>lenient_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lenient_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted</td>\n",
       "      <td>42</td>\n",
       "      <td>0.812704</td>\n",
       "      <td>0.670476</td>\n",
       "      <td>0.951479</td>\n",
       "      <td>0.655930</td>\n",
       "      <td>0.821037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted</td>\n",
       "      <td>52</td>\n",
       "      <td>1.159253</td>\n",
       "      <td>0.674565</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>0.852299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted</td>\n",
       "      <td>62</td>\n",
       "      <td>1.062273</td>\n",
       "      <td>0.672352</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.669241</td>\n",
       "      <td>0.865117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted</td>\n",
       "      <td>88</td>\n",
       "      <td>0.844411</td>\n",
       "      <td>0.689547</td>\n",
       "      <td>0.963743</td>\n",
       "      <td>0.662785</td>\n",
       "      <td>0.832942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted</td>\n",
       "      <td>99</td>\n",
       "      <td>0.846857</td>\n",
       "      <td>0.679166</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.689609</td>\n",
       "      <td>0.835926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>focal</td>\n",
       "      <td>42</td>\n",
       "      <td>0.241446</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.964871</td>\n",
       "      <td>0.644519</td>\n",
       "      <td>0.839791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>focal</td>\n",
       "      <td>52</td>\n",
       "      <td>0.246164</td>\n",
       "      <td>0.675118</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.636619</td>\n",
       "      <td>0.844260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>focal</td>\n",
       "      <td>62</td>\n",
       "      <td>0.255305</td>\n",
       "      <td>0.689710</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.650224</td>\n",
       "      <td>0.851109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>focal</td>\n",
       "      <td>88</td>\n",
       "      <td>0.227770</td>\n",
       "      <td>0.686596</td>\n",
       "      <td>0.965438</td>\n",
       "      <td>0.627593</td>\n",
       "      <td>0.800179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>focal</td>\n",
       "      <td>99</td>\n",
       "      <td>0.243520</td>\n",
       "      <td>0.693894</td>\n",
       "      <td>0.962353</td>\n",
       "      <td>0.655554</td>\n",
       "      <td>0.843069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ce</td>\n",
       "      <td>42</td>\n",
       "      <td>0.532795</td>\n",
       "      <td>0.629411</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.876268</td>\n",
       "      <td>0.933063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ce</td>\n",
       "      <td>52</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>0.686720</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.886410</td>\n",
       "      <td>0.935091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ce</td>\n",
       "      <td>62</td>\n",
       "      <td>0.489638</td>\n",
       "      <td>0.649745</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.937120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ce</td>\n",
       "      <td>88</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0.956419</td>\n",
       "      <td>0.868154</td>\n",
       "      <td>0.924949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ce</td>\n",
       "      <td>99</td>\n",
       "      <td>0.515535</td>\n",
       "      <td>0.730862</td>\n",
       "      <td>0.965922</td>\n",
       "      <td>0.888438</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_type  seed      loss  macro_f1  lenient_f1  accuracy  lenient_accuracy\n",
       "0   weighted    42  0.812704  0.670476    0.951479  0.655930          0.821037\n",
       "1   weighted    52  1.159253  0.674565    0.965922  0.639472          0.852299\n",
       "2   weighted    62  1.062273  0.672352    0.949275  0.669241          0.865117\n",
       "3   weighted    88  0.844411  0.689547    0.963743  0.662785          0.832942\n",
       "4   weighted    99  0.846857  0.679166    0.954976  0.689609          0.835926\n",
       "5      focal    42  0.241446  0.691545    0.964871  0.644519          0.839791\n",
       "6      focal    52  0.246164  0.675118    0.963572  0.636619          0.844260\n",
       "7      focal    62  0.255305  0.689710    0.964706  0.650224          0.851109\n",
       "8      focal    88  0.227770  0.686596    0.965438  0.627593          0.800179\n",
       "9      focal    99  0.243520  0.693894    0.962353  0.655554          0.843069\n",
       "10        ce    42  0.532795  0.629411    0.961039  0.876268          0.933063\n",
       "11        ce    52  0.521937  0.686720    0.962264  0.886410          0.935091\n",
       "12        ce    62  0.489638  0.649745    0.963400  0.882353          0.937120\n",
       "13        ce    88  0.546296  0.629348    0.956419  0.868154          0.924949\n",
       "14        ce    99  0.515535  0.730862    0.965922  0.888438          0.941176"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only context == False rows\n",
    "df_ce = df_context[df_context[\"context\"] == True].copy()\n",
    "df_ce[\"loss_type\"] = \"ce\"\n",
    "df_ce = df_ce[[\"loss_type\", \"seed\", \"loss\", \"macro_f1\", \"lenient_f1\", \"accuracy\", \"lenient_accuracy\"]]\n",
    "df_loss = pd.concat([df_loss, df_ce], ignore_index=True)\n",
    "df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cc580e5-b3e7-4e70-9bc0-71425b77f529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_loss, x=\"loss_type\", y=\"macro_f1\")\n",
    "plt.title(\"Macro F1 Score Across Loss Functions\")\n",
    "plt.ylabel(\"Macro F1\")\n",
    "plt.xlabel(\"Loss Function\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1eaff-32af-42fe-9ec8-5dcdb811d49c",
   "metadata": {},
   "source": [
    "Summary:\n",
    "Context is the best for roberta-large.\n",
    "Focal loss is the best for roberta-large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff4e67a2-a32c-4b19-a446-174928d44145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=1.0, seed=42 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.270674</td>\n",
       "      <td>0.577539</td>\n",
       "      <td>0.624311</td>\n",
       "      <td>0.801076</td>\n",
       "      <td>0.960557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.320377</td>\n",
       "      <td>0.598281</td>\n",
       "      <td>0.649943</td>\n",
       "      <td>0.818346</td>\n",
       "      <td>0.966396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.317439</td>\n",
       "      <td>0.605500</td>\n",
       "      <td>0.629862</td>\n",
       "      <td>0.843966</td>\n",
       "      <td>0.957346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.328679</td>\n",
       "      <td>0.628719</td>\n",
       "      <td>0.663761</td>\n",
       "      <td>0.849918</td>\n",
       "      <td>0.963486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 45   1  27]\n",
      " [  2   4  25]\n",
      " [  4   1 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.62      0.73        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.81      0.58      0.62       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 47   2  24]\n",
      " [  1   5  25]\n",
      " [  2   2 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.64      0.76        73\n",
      "         TSE       0.56      0.16      0.25        31\n",
      "         Yes       0.89      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.60      0.65       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   4  25]\n",
      " [ 14   1 374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.77      0.73      0.75        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.89      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.78      0.61      0.63       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   6  23]\n",
      " [  9   4 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.73      0.77        73\n",
      "         TSE       0.55      0.19      0.29        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.76      0.63      0.66       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   6  23]\n",
      " [  9   4 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.73      0.77        73\n",
      "         TSE       0.55      0.19      0.29        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.76      0.63      0.66       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=1.0, seed=52 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.289911</td>\n",
       "      <td>0.562597</td>\n",
       "      <td>0.591107</td>\n",
       "      <td>0.768624</td>\n",
       "      <td>0.945029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.313896</td>\n",
       "      <td>0.592095</td>\n",
       "      <td>0.641248</td>\n",
       "      <td>0.825196</td>\n",
       "      <td>0.967517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.300970</td>\n",
       "      <td>0.588761</td>\n",
       "      <td>0.622978</td>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.963743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.328855</td>\n",
       "      <td>0.608070</td>\n",
       "      <td>0.633761</td>\n",
       "      <td>0.848728</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 42   4  27]\n",
      " [  3   5  23]\n",
      " [ 13   6 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.72      0.58      0.64        73\n",
      "         TSE       0.33      0.16      0.22        31\n",
      "         Yes       0.88      0.95      0.91       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.65      0.56      0.59       493\n",
      "weighted avg       0.82      0.85      0.83       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  0   4  27]\n",
      " [  3   1 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.66      0.77        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.83      0.59      0.64       493\n",
      "weighted avg       0.88      0.89      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1  22]\n",
      " [  2   3  26]\n",
      " [  6   0 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.68      0.76        73\n",
      "         TSE       0.75      0.10      0.17        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.83      0.59      0.62       493\n",
      "weighted avg       0.88      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  3   4  24]\n",
      " [  9   3 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.73      0.77        73\n",
      "         TSE       0.44      0.13      0.20        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.72      0.61      0.63       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  0   4  27]\n",
      " [  3   1 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.66      0.77        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.83      0.59      0.64       493\n",
      "weighted avg       0.88      0.89      0.86       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=1.0, seed=62 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.347949</td>\n",
       "      <td>0.553051</td>\n",
       "      <td>0.501540</td>\n",
       "      <td>0.815705</td>\n",
       "      <td>0.907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.321690</td>\n",
       "      <td>0.593997</td>\n",
       "      <td>0.637718</td>\n",
       "      <td>0.813584</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>0.312661</td>\n",
       "      <td>0.618730</td>\n",
       "      <td>0.653203</td>\n",
       "      <td>0.833839</td>\n",
       "      <td>0.958775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.328810</td>\n",
       "      <td>0.636619</td>\n",
       "      <td>0.675118</td>\n",
       "      <td>0.844260</td>\n",
       "      <td>0.963572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 56   0  17]\n",
      " [ 15   0  16]\n",
      " [ 42   0 347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.77      0.60        73\n",
      "         TSE       0.00      0.00      0.00        31\n",
      "         Yes       0.91      0.89      0.90       389\n",
      "\n",
      "    accuracy                           0.82       493\n",
      "   macro avg       0.47      0.55      0.50       493\n",
      "weighted avg       0.79      0.82      0.80       493\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 47   2  24]\n",
      " [  1   5  25]\n",
      " [  6   3 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.64      0.74        73\n",
      "         TSE       0.50      0.16      0.24        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.59      0.64       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  2   6  23]\n",
      " [ 11   3 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.70      0.74        73\n",
      "         TSE       0.55      0.19      0.29        31\n",
      "         Yes       0.90      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.62      0.65       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   7  21]\n",
      " [  7   4 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.76      0.64      0.68       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   7  21]\n",
      " [  7   4 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.76      0.64      0.68       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=1.0, seed=88 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.273635</td>\n",
       "      <td>0.589912</td>\n",
       "      <td>0.650051</td>\n",
       "      <td>0.792140</td>\n",
       "      <td>0.963134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.310156</td>\n",
       "      <td>0.590287</td>\n",
       "      <td>0.634821</td>\n",
       "      <td>0.806735</td>\n",
       "      <td>0.960465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.298581</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.662579</td>\n",
       "      <td>0.836220</td>\n",
       "      <td>0.961222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.313142</td>\n",
       "      <td>0.654791</td>\n",
       "      <td>0.692368</td>\n",
       "      <td>0.855577</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 43   1  29]\n",
      " [  0   6  25]\n",
      " [  2   3 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.96      0.59      0.73        73\n",
      "         TSE       0.60      0.19      0.29        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.81      0.59      0.65       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 46   2  25]\n",
      " [  2   5  24]\n",
      " [  5   3 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.63      0.73        73\n",
      "         TSE       0.50      0.16      0.24        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.59      0.63       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  2   6  23]\n",
      " [  9   2 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.70      0.76        73\n",
      "         TSE       0.67      0.19      0.30        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.79      0.62      0.66       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   2  17]\n",
      " [  2   8  21]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.74      0.78        73\n",
      "         TSE       0.62      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.78      0.65      0.69       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 54   2  17]\n",
      " [  2   8  21]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.74      0.78        73\n",
      "         TSE       0.62      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.78      0.65      0.69       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=1.0, seed=99 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:14, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.309359</td>\n",
       "      <td>0.543192</td>\n",
       "      <td>0.583846</td>\n",
       "      <td>0.785290</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.324235</td>\n",
       "      <td>0.601897</td>\n",
       "      <td>0.651520</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>0.961672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.321964</td>\n",
       "      <td>0.609691</td>\n",
       "      <td>0.641972</td>\n",
       "      <td>0.835029</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.326034</td>\n",
       "      <td>0.636901</td>\n",
       "      <td>0.664664</td>\n",
       "      <td>0.846347</td>\n",
       "      <td>0.959811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 42   2  29]\n",
      " [  0   2  29]\n",
      " [  2   2 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.58      0.72        73\n",
      "         TSE       0.33      0.06      0.11        31\n",
      "         Yes       0.87      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.54      0.58       493\n",
      "weighted avg       0.85      0.87      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 46   2  25]\n",
      " [  2   6  23]\n",
      " [  4   3 382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.63      0.74        73\n",
      "         TSE       0.55      0.19      0.29        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.77      0.60      0.65       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  3   5  23]\n",
      " [  9   3 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.70      0.75        73\n",
      "         TSE       0.50      0.16      0.24        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.61      0.64       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  4   7  20]\n",
      " [ 10   6 373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.73      0.76        73\n",
      "         TSE       0.47      0.23      0.30        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.72      0.64      0.66       493\n",
      "weighted avg       0.86      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  4   7  20]\n",
      " [ 10   6 373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.73      0.76        73\n",
      "         TSE       0.47      0.23      0.30        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.72      0.64      0.66       493\n",
      "weighted avg       0.86      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=2.0, seed=42 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>0.565061</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.949233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204400</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.591238</td>\n",
       "      <td>0.633951</td>\n",
       "      <td>0.819243</td>\n",
       "      <td>0.961494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.194565</td>\n",
       "      <td>0.615114</td>\n",
       "      <td>0.649623</td>\n",
       "      <td>0.841879</td>\n",
       "      <td>0.961131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.214702</td>\n",
       "      <td>0.628437</td>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.845450</td>\n",
       "      <td>0.964789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  5   3  23]\n",
      " [ 13  10 366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.73      0.66      0.69        73\n",
      "         TSE       0.21      0.10      0.13        31\n",
      "         Yes       0.89      0.94      0.91       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.61      0.57      0.58       493\n",
      "weighted avg       0.82      0.85      0.83       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  3   4  24]\n",
      " [  5   0 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.66      0.74        73\n",
      "         TSE       0.80      0.13      0.22        31\n",
      "         Yes       0.89      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.85      0.59      0.63       493\n",
      "weighted avg       0.88      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   1  20]\n",
      " [  3   5  23]\n",
      " [  9   2 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.71      0.76        73\n",
      "         TSE       0.62      0.16      0.26        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.78      0.62      0.65       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   6  22]\n",
      " [  6   2 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.71      0.78        73\n",
      "         TSE       0.60      0.19      0.29        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.63      0.67       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   6  22]\n",
      " [  6   2 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.71      0.78        73\n",
      "         TSE       0.60      0.19      0.29        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.63      0.67       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=2.0, seed=52 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='744' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [744/992 01:38 < 00:33, 7.50 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.172333</td>\n",
       "      <td>0.599326</td>\n",
       "      <td>0.641046</td>\n",
       "      <td>0.809116</td>\n",
       "      <td>0.962877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>0.557747</td>\n",
       "      <td>0.593532</td>\n",
       "      <td>0.802267</td>\n",
       "      <td>0.961761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.628123</td>\n",
       "      <td>0.855577</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 46   4  23]\n",
      " [  2   6  23]\n",
      " [  3   7 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.63      0.74        73\n",
      "         TSE       0.35      0.19      0.25        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.60      0.64       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45   1  27]\n",
      " [  2   2  27]\n",
      " [  3   0 386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.62      0.73        73\n",
      "         TSE       0.67      0.06      0.12        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.81      0.56      0.59       493\n",
      "weighted avg       0.87      0.88      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   1  18]\n",
      " [  3   3  25]\n",
      " [  9   0 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.74      0.78        73\n",
      "         TSE       0.75      0.10      0.17        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.82      0.60      0.63       493\n",
      "weighted avg       0.88      0.89      0.86       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 46   4  23]\n",
      " [  2   6  23]\n",
      " [  3   7 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.63      0.74        73\n",
      "         TSE       0.35      0.19      0.25        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.60      0.64       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=2.0, seed=62 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.199029</td>\n",
       "      <td>0.561740</td>\n",
       "      <td>0.590386</td>\n",
       "      <td>0.769814</td>\n",
       "      <td>0.946262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.198826</td>\n",
       "      <td>0.592951</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.825196</td>\n",
       "      <td>0.967517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.230357</td>\n",
       "      <td>0.587422</td>\n",
       "      <td>0.604097</td>\n",
       "      <td>0.848728</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.225371</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>0.678151</td>\n",
       "      <td>0.848728</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 42   4  27]\n",
      " [  2   5  24]\n",
      " [ 13   7 369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.74      0.58      0.65        73\n",
      "         TSE       0.31      0.16      0.21        31\n",
      "         Yes       0.88      0.95      0.91       389\n",
      "\n",
      "    accuracy                           0.84       493\n",
      "   macro avg       0.64      0.56      0.59       493\n",
      "weighted avg       0.82      0.84      0.83       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  1   4  26]\n",
      " [  2   1 386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.66      0.77        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.89      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.83      0.59      0.64       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   2  27]\n",
      " [ 10   1 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.73      0.77        73\n",
      "         TSE       0.50      0.06      0.11        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.59      0.60       493\n",
      "weighted avg       0.86      0.88      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   7  22]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.73      0.77        73\n",
      "         TSE       0.64      0.23      0.33        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.78      0.64      0.68       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  2   7  22]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.73      0.77        73\n",
      "         TSE       0.64      0.23      0.33        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.78      0.64      0.68       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=2.0, seed=88 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.204427</td>\n",
       "      <td>0.496298</td>\n",
       "      <td>0.542832</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.950226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.217672</td>\n",
       "      <td>0.585815</td>\n",
       "      <td>0.629416</td>\n",
       "      <td>0.813584</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.206997</td>\n",
       "      <td>0.601509</td>\n",
       "      <td>0.635127</td>\n",
       "      <td>0.837410</td>\n",
       "      <td>0.962441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.221221</td>\n",
       "      <td>0.672587</td>\n",
       "      <td>0.713135</td>\n",
       "      <td>0.849918</td>\n",
       "      <td>0.963486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 29   7  37]\n",
      " [  0   3  28]\n",
      " [  0   2 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.40      0.57        73\n",
      "         TSE       0.25      0.10      0.14        31\n",
      "         Yes       0.86      0.99      0.92       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.70      0.50      0.54       493\n",
      "weighted avg       0.84      0.85      0.82       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 47   1  25]\n",
      " [  2   4  25]\n",
      " [  5   1 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.64      0.74        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.88      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.81      0.59      0.63       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  3   4  24]\n",
      " [  7   2 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.70      0.76        73\n",
      "         TSE       0.57      0.13      0.21        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.77      0.60      0.64       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  3  10  18]\n",
      " [  8   4 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.73      0.77        73\n",
      "         TSE       0.62      0.32      0.43        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.67      0.71       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  3  10  18]\n",
      " [  8   4 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.73      0.77        73\n",
      "         TSE       0.62      0.32      0.43        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.79      0.67      0.71       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.9, gamma=2.0, seed=99 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.184386</td>\n",
       "      <td>0.544049</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.784100</td>\n",
       "      <td>0.960829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.195843</td>\n",
       "      <td>0.582869</td>\n",
       "      <td>0.635253</td>\n",
       "      <td>0.796608</td>\n",
       "      <td>0.961850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.213583</td>\n",
       "      <td>0.618448</td>\n",
       "      <td>0.660743</td>\n",
       "      <td>0.829371</td>\n",
       "      <td>0.960094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.236976</td>\n",
       "      <td>0.646703</td>\n",
       "      <td>0.676894</td>\n",
       "      <td>0.833839</td>\n",
       "      <td>0.958775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 42   1  30]\n",
      " [  0   2  29]\n",
      " [  3   0 386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.58      0.71        73\n",
      "         TSE       0.67      0.06      0.12        31\n",
      "         Yes       0.87      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.82      0.54      0.59       493\n",
      "weighted avg       0.86      0.87      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 44   2  27]\n",
      " [  0   5  26]\n",
      " [  4   2 383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.60      0.73        73\n",
      "         TSE       0.56      0.16      0.25        31\n",
      "         Yes       0.88      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.78      0.58      0.64       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   2  21]\n",
      " [  3   6  22]\n",
      " [  8   1 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.68      0.75        73\n",
      "         TSE       0.67      0.19      0.30        31\n",
      "         Yes       0.90      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.79      0.62      0.66       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  2   9  20]\n",
      " [ 11   8 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.70      0.74        73\n",
      "         TSE       0.47      0.29      0.36        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.65      0.68       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  2   9  20]\n",
      " [ 11   8 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.70      0.74        73\n",
      "         TSE       0.47      0.29      0.36        31\n",
      "         Yes       0.90      0.95      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.65      0.68       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=1.0, seed=42 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.336600</td>\n",
       "      <td>0.272737</td>\n",
       "      <td>0.593997</td>\n",
       "      <td>0.639528</td>\n",
       "      <td>0.817156</td>\n",
       "      <td>0.965197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.305446</td>\n",
       "      <td>0.608177</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.818346</td>\n",
       "      <td>0.966396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>0.326721</td>\n",
       "      <td>0.619105</td>\n",
       "      <td>0.643923</td>\n",
       "      <td>0.850815</td>\n",
       "      <td>0.958482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.337035</td>\n",
       "      <td>0.644801</td>\n",
       "      <td>0.680763</td>\n",
       "      <td>0.845450</td>\n",
       "      <td>0.964789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 47   1  25]\n",
      " [  1   5  25]\n",
      " [  3   6 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.64      0.76        73\n",
      "         TSE       0.42      0.16      0.23        31\n",
      "         Yes       0.88      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.59      0.64       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 47   1  25]\n",
      " [  0   6  25]\n",
      " [  3   2 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.94      0.64      0.76        73\n",
      "         TSE       0.67      0.19      0.30        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.83      0.61      0.67       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   1  18]\n",
      " [  2   5  24]\n",
      " [ 14   3 372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.77      0.74      0.76        73\n",
      "         TSE       0.56      0.16      0.25        31\n",
      "         Yes       0.90      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.74      0.62      0.64       493\n",
      "weighted avg       0.86      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  2   8  21]\n",
      " [  7   7 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.71      0.78        73\n",
      "         TSE       0.47      0.26      0.33        31\n",
      "         Yes       0.90      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.64      0.68       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  2   8  21]\n",
      " [  7   7 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.71      0.78        73\n",
      "         TSE       0.47      0.26      0.33        31\n",
      "         Yes       0.90      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.64      0.68       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=1.0, seed=52 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.287032</td>\n",
       "      <td>0.578009</td>\n",
       "      <td>0.604409</td>\n",
       "      <td>0.791553</td>\n",
       "      <td>0.950820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.278288</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.657960</td>\n",
       "      <td>0.839791</td>\n",
       "      <td>0.964871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.317346</td>\n",
       "      <td>0.597036</td>\n",
       "      <td>0.626024</td>\n",
       "      <td>0.844260</td>\n",
       "      <td>0.963572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.315362</td>\n",
       "      <td>0.614350</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.859149</td>\n",
       "      <td>0.967059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 45   6  22]\n",
      " [  3   5  23]\n",
      " [ 11   6 372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.76      0.62      0.68        73\n",
      "         TSE       0.29      0.16      0.21        31\n",
      "         Yes       0.89      0.96      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.65      0.58      0.60       493\n",
      "weighted avg       0.84      0.86      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  3   6  22]\n",
      " [  5   6 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.70      0.77        73\n",
      "         TSE       0.43      0.19      0.27        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.73      0.62      0.66       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   1  20]\n",
      " [  3   3  25]\n",
      " [  7   0 382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.75      0.10      0.17        31\n",
      "         Yes       0.89      0.98      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.83      0.60      0.63       493\n",
      "weighted avg       0.88      0.89      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   2  17]\n",
      " [  3   4  24]\n",
      " [  6   4 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.74      0.79        73\n",
      "         TSE       0.40      0.13      0.20        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.72      0.61      0.64       493\n",
      "weighted avg       0.86      0.89      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  3   6  22]\n",
      " [  5   6 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.70      0.77        73\n",
      "         TSE       0.43      0.19      0.27        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.73      0.62      0.66       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=1.0, seed=62 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.269435</td>\n",
       "      <td>0.557172</td>\n",
       "      <td>0.582559</td>\n",
       "      <td>0.801973</td>\n",
       "      <td>0.955607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>0.305780</td>\n",
       "      <td>0.631678</td>\n",
       "      <td>0.688106</td>\n",
       "      <td>0.824005</td>\n",
       "      <td>0.966318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.335481</td>\n",
       "      <td>0.588185</td>\n",
       "      <td>0.612155</td>\n",
       "      <td>0.835029</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.319876</td>\n",
       "      <td>0.632053</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.836220</td>\n",
       "      <td>0.961222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 46   1  26]\n",
      " [  3   2  26]\n",
      " [  8   1 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.63      0.71        73\n",
      "         TSE       0.50      0.06      0.11        31\n",
      "         Yes       0.88      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.73      0.56      0.58       493\n",
      "weighted avg       0.85      0.87      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  0   8  23]\n",
      " [  4   4 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.66      0.77        73\n",
      "         TSE       0.62      0.26      0.36        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.81      0.63      0.69       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  3   3  25]\n",
      " [  9   3 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.70      0.75        73\n",
      "         TSE       0.43      0.10      0.16        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.71      0.59      0.61       493\n",
      "weighted avg       0.85      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  3   7  21]\n",
      " [  8   3 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.70      0.76        73\n",
      "         TSE       0.64      0.23      0.33        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.79      0.63      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  0   8  23]\n",
      " [  4   4 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.66      0.77        73\n",
      "         TSE       0.62      0.26      0.36        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.81      0.63      0.69       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=1.0, seed=88 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.276970</td>\n",
       "      <td>0.554708</td>\n",
       "      <td>0.600965</td>\n",
       "      <td>0.769211</td>\n",
       "      <td>0.957422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.310928</td>\n",
       "      <td>0.605981</td>\n",
       "      <td>0.640719</td>\n",
       "      <td>0.830561</td>\n",
       "      <td>0.961313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.307520</td>\n",
       "      <td>0.609784</td>\n",
       "      <td>0.636734</td>\n",
       "      <td>0.848728</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.324595</td>\n",
       "      <td>0.647372</td>\n",
       "      <td>0.687964</td>\n",
       "      <td>0.844260</td>\n",
       "      <td>0.963572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 40   5  28]\n",
      " [  1   4  26]\n",
      " [  3   2 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.55      0.68        73\n",
      "         TSE       0.36      0.13      0.19        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.72      0.55      0.60       493\n",
      "weighted avg       0.85      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   3  20]\n",
      " [  2   5  24]\n",
      " [  8   3 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.68      0.75        73\n",
      "         TSE       0.45      0.16      0.24        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.73      0.61      0.64       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  4   4  23]\n",
      " [  8   2 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.73      0.77        73\n",
      "         TSE       0.50      0.13      0.21        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.61      0.64       493\n",
      "weighted avg       0.86      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   8  20]\n",
      " [  7   4 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.77      0.65      0.69       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   8  20]\n",
      " [  7   4 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.71      0.77        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.77      0.65      0.69       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=1.0, seed=99 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.279196</td>\n",
       "      <td>0.556891</td>\n",
       "      <td>0.590389</td>\n",
       "      <td>0.801076</td>\n",
       "      <td>0.960557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.293199</td>\n",
       "      <td>0.565166</td>\n",
       "      <td>0.594687</td>\n",
       "      <td>0.812394</td>\n",
       "      <td>0.960373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.308366</td>\n",
       "      <td>0.598081</td>\n",
       "      <td>0.624689</td>\n",
       "      <td>0.833839</td>\n",
       "      <td>0.958775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.334642</td>\n",
       "      <td>0.634905</td>\n",
       "      <td>0.669993</td>\n",
       "      <td>0.843069</td>\n",
       "      <td>0.962353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 45   1  27]\n",
      " [  3   2  26]\n",
      " [  3   1 385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.62      0.73        73\n",
      "         TSE       0.50      0.06      0.11        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.56      0.59       493\n",
      "weighted avg       0.86      0.88      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 47   1  25]\n",
      " [  3   2  26]\n",
      " [  5   0 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.64      0.73        73\n",
      "         TSE       0.67      0.06      0.12        31\n",
      "         Yes       0.88      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.80      0.57      0.59       493\n",
      "weighted avg       0.86      0.88      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  3   4  24]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.70      0.74        73\n",
      "         TSE       0.44      0.13      0.20        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.71      0.60      0.62       493\n",
      "weighted avg       0.85      0.87      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   7  21]\n",
      " [  8   5 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.71      0.76        73\n",
      "         TSE       0.50      0.23      0.31        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.63      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   7  21]\n",
      " [  8   5 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.71      0.76        73\n",
      "         TSE       0.50      0.23      0.31        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.63      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=2.0, seed=42 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.179249</td>\n",
       "      <td>0.603987</td>\n",
       "      <td>0.639379</td>\n",
       "      <td>0.794227</td>\n",
       "      <td>0.959444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.205700</td>\n",
       "      <td>0.207384</td>\n",
       "      <td>0.628062</td>\n",
       "      <td>0.682460</td>\n",
       "      <td>0.833235</td>\n",
       "      <td>0.969838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.213726</td>\n",
       "      <td>0.606357</td>\n",
       "      <td>0.630546</td>\n",
       "      <td>0.846347</td>\n",
       "      <td>0.959811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.222036</td>\n",
       "      <td>0.647654</td>\n",
       "      <td>0.679943</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>0.958580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 44   4  25]\n",
      " [  0   8  23]\n",
      " [  6  13 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.60      0.72        73\n",
      "         TSE       0.32      0.26      0.29        31\n",
      "         Yes       0.89      0.95      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.70      0.60      0.64       493\n",
      "weighted avg       0.85      0.86      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49   2  22]\n",
      " [  1   7  23]\n",
      " [  1   4 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.96      0.67      0.79        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.90      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.80      0.63      0.68       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   1  19]\n",
      " [  3   4  24]\n",
      " [ 11   3 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.79      0.73      0.76        73\n",
      "         TSE       0.50      0.13      0.21        31\n",
      "         Yes       0.90      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.73      0.61      0.63       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  3   8  20]\n",
      " [ 12   4 373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.78      0.73      0.75        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.65      0.68       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 49   2  22]\n",
      " [  1   7  23]\n",
      " [  1   4 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.96      0.67      0.79        73\n",
      "         TSE       0.54      0.23      0.32        31\n",
      "         Yes       0.90      0.99      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.80      0.63      0.68       493\n",
      "weighted avg       0.88      0.89      0.88       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=2.0, seed=52 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.211480</td>\n",
       "      <td>0.535092</td>\n",
       "      <td>0.535574</td>\n",
       "      <td>0.802870</td>\n",
       "      <td>0.950588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.236616</td>\n",
       "      <td>0.593233</td>\n",
       "      <td>0.634019</td>\n",
       "      <td>0.829664</td>\n",
       "      <td>0.966240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.200540</td>\n",
       "      <td>0.590756</td>\n",
       "      <td>0.618624</td>\n",
       "      <td>0.837410</td>\n",
       "      <td>0.962441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.228360</td>\n",
       "      <td>0.632053</td>\n",
       "      <td>0.669703</td>\n",
       "      <td>0.837410</td>\n",
       "      <td>0.962441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 47   1  25]\n",
      " [  2   0  29]\n",
      " [ 14   1 374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.75      0.64      0.69        73\n",
      "         TSE       0.00      0.00      0.00        31\n",
      "         Yes       0.87      0.96      0.92       389\n",
      "\n",
      "    accuracy                           0.85       493\n",
      "   macro avg       0.54      0.54      0.54       493\n",
      "weighted avg       0.80      0.85      0.82       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49   1  23]\n",
      " [  1   4  26]\n",
      " [  4   4 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.67      0.77        73\n",
      "         TSE       0.44      0.13      0.20        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.59      0.63       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  3   3  25]\n",
      " [  7   2 380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.70      0.76        73\n",
      "         TSE       0.50      0.10      0.16        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.74      0.59      0.62       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  4   7  20]\n",
      " [  6   5 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.70      0.76        73\n",
      "         TSE       0.50      0.23      0.31        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.63      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 51   2  20]\n",
      " [  4   7  20]\n",
      " [  6   5 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.70      0.76        73\n",
      "         TSE       0.50      0.23      0.31        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.63      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=2.0, seed=62 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.172381</td>\n",
       "      <td>0.565448</td>\n",
       "      <td>0.590696</td>\n",
       "      <td>0.818053</td>\n",
       "      <td>0.960280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.210469</td>\n",
       "      <td>0.601990</td>\n",
       "      <td>0.653123</td>\n",
       "      <td>0.822815</td>\n",
       "      <td>0.965116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226600</td>\n",
       "      <td>0.208704</td>\n",
       "      <td>0.586472</td>\n",
       "      <td>0.609068</td>\n",
       "      <td>0.833839</td>\n",
       "      <td>0.958775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.216512</td>\n",
       "      <td>0.617966</td>\n",
       "      <td>0.646498</td>\n",
       "      <td>0.847538</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  2   2  27]\n",
      " [  7   3 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.66      0.74        73\n",
      "         TSE       0.33      0.06      0.11        31\n",
      "         Yes       0.88      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.69      0.57      0.59       493\n",
      "weighted avg       0.84      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  1   5  25]\n",
      " [  4   1 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.66      0.76        73\n",
      "         TSE       0.71      0.16      0.26        31\n",
      "         Yes       0.89      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.84      0.60      0.65       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  2   3  26]\n",
      " [ 11   3 375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.70      0.74        73\n",
      "         TSE       0.43      0.10      0.16        31\n",
      "         Yes       0.89      0.96      0.92       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.70      0.59      0.61       493\n",
      "weighted avg       0.85      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 53   2  18]\n",
      " [  3   5  23]\n",
      " [ 10   3 376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.73      0.76        73\n",
      "         TSE       0.50      0.16      0.24        31\n",
      "         Yes       0.90      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.73      0.62      0.65       493\n",
      "weighted avg       0.86      0.88      0.86       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 48   1  24]\n",
      " [  1   5  25]\n",
      " [  4   1 384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.66      0.76        73\n",
      "         TSE       0.71      0.16      0.26        31\n",
      "         Yes       0.89      0.99      0.93       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.84      0.60      0.65       493\n",
      "weighted avg       0.88      0.89      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=2.0, seed=88 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.188652</td>\n",
       "      <td>0.609879</td>\n",
       "      <td>0.641260</td>\n",
       "      <td>0.834132</td>\n",
       "      <td>0.964953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.216711</td>\n",
       "      <td>0.614739</td>\n",
       "      <td>0.665011</td>\n",
       "      <td>0.830855</td>\n",
       "      <td>0.967442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.211894</td>\n",
       "      <td>0.588185</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.836220</td>\n",
       "      <td>0.961222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.239193</td>\n",
       "      <td>0.646515</td>\n",
       "      <td>0.685636</td>\n",
       "      <td>0.843069</td>\n",
       "      <td>0.962353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 50   1  22]\n",
      " [  1   6  24]\n",
      " [  6  13 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.68      0.77        73\n",
      "         TSE       0.30      0.19      0.24        31\n",
      "         Yes       0.89      0.95      0.92       389\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.69      0.61      0.64       493\n",
      "weighted avg       0.85      0.86      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49   1  23]\n",
      " [  0   6  25]\n",
      " [  4   4 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.92      0.67      0.78        73\n",
      "         TSE       0.55      0.19      0.29        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.79      0.61      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   1  21]\n",
      " [  2   3  26]\n",
      " [  9   3 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.70      0.76        73\n",
      "         TSE       0.43      0.10      0.16        31\n",
      "         Yes       0.89      0.97      0.93       389\n",
      "\n",
      "    accuracy                           0.87       493\n",
      "   macro avg       0.71      0.59      0.61       493\n",
      "weighted avg       0.85      0.87      0.85       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   8  20]\n",
      " [  8   4 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.71      0.76        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.77      0.65      0.69       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 52   2  19]\n",
      " [  3   8  20]\n",
      " [  8   4 377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.71      0.76        73\n",
      "         TSE       0.57      0.26      0.36        31\n",
      "         Yes       0.91      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.89       493\n",
      "   macro avg       0.77      0.65      0.69       493\n",
      "weighted avg       0.87      0.89      0.87       493\n",
      "\n",
      "\n",
      "=== CB‑Focal: beta=0.99, gamma=2.0, seed=99 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [992/992 02:08, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Lenient Accuracy</th>\n",
       "      <th>Lenient F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.248584</td>\n",
       "      <td>0.587718</td>\n",
       "      <td>0.612097</td>\n",
       "      <td>0.772489</td>\n",
       "      <td>0.954913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.207473</td>\n",
       "      <td>0.628344</td>\n",
       "      <td>0.671801</td>\n",
       "      <td>0.829371</td>\n",
       "      <td>0.960094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.215852</td>\n",
       "      <td>0.598656</td>\n",
       "      <td>0.637853</td>\n",
       "      <td>0.832942</td>\n",
       "      <td>0.963743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.214952</td>\n",
       "      <td>0.662116</td>\n",
       "      <td>0.694381</td>\n",
       "      <td>0.855577</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 41  10  22]\n",
      " [  3   8  20]\n",
      " [  4  18 367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.56      0.68        73\n",
      "         TSE       0.22      0.26      0.24        31\n",
      "         Yes       0.90      0.94      0.92       389\n",
      "\n",
      "    accuracy                           0.84       493\n",
      "   macro avg       0.66      0.59      0.61       493\n",
      "weighted avg       0.85      0.84      0.84       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   2  21]\n",
      " [  3   7  21]\n",
      " [  8   2 379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.68      0.75        73\n",
      "         TSE       0.64      0.23      0.33        31\n",
      "         Yes       0.90      0.97      0.94       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.79      0.63      0.67       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1  22]\n",
      " [  2   4  25]\n",
      " [  6   1 382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.68      0.76        73\n",
      "         TSE       0.67      0.13      0.22        31\n",
      "         Yes       0.89      0.98      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.81      0.60      0.64       493\n",
      "weighted avg       0.87      0.88      0.86       493\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   2  17]\n",
      " [  1   9  21]\n",
      " [ 11   6 372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.74      0.78        73\n",
      "         TSE       0.53      0.29      0.38        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.66      0.69       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 54   2  17]\n",
      " [  1   9  21]\n",
      " [ 11   6 372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.74      0.78        73\n",
      "         TSE       0.53      0.29      0.38        31\n",
      "         Yes       0.91      0.96      0.93       389\n",
      "\n",
      "    accuracy                           0.88       493\n",
      "   macro avg       0.75      0.66      0.69       493\n",
      "weighted avg       0.87      0.88      0.87       493\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.99</th>\n",
       "      <th>2.0</th>\n",
       "      <td>0.677060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.676957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.90</th>\n",
       "      <th>2.0</th>\n",
       "      <td>0.675737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.667432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            macro_f1\n",
       "beta gamma          \n",
       "0.99 2.0    0.677060\n",
       "     1.0    0.676957\n",
       "0.90 2.0    0.675737\n",
       "     1.0    0.667432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "samples_per_cls = [Counter(train_df[LABEL])[i] for i in range(3)]\n",
    "\n",
    "class CBFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Class‑Balanced Focal Loss\n",
    "        - beta controls how aggressively rare classes are up‑weighted\n",
    "        - gamma is the focal‐loss focusing parameter\n",
    "    \"\"\"\n",
    "    def __init__(self, samples_per_cls, beta=0.99, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        n_cls = len(samples_per_cls)\n",
    "\n",
    "        effective_num = 1.0 - torch.pow(torch.tensor(beta), torch.tensor(samples_per_cls))\n",
    "        self.weights = ((1.0 - beta) / effective_num).float()          \n",
    "        self.weights = self.weights / self.weights.sum() * n_cls       # re‑normalise\n",
    "        self.gamma   = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        logpt = F.log_softmax(logits, dim=-1)          # log‑prob for every class\n",
    "        pt    = torch.exp(logpt)                       # prob for every class\n",
    "\n",
    "        logpt = logpt.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        pt    = pt.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        alpha_t = self.weights.to(logits.device).gather(0, targets)\n",
    "        loss = -alpha_t * (1 - pt) ** self.gamma * logpt\n",
    "\n",
    "        return loss.mean() if self.reduction == 'mean' else loss.sum()\n",
    "\n",
    "\n",
    "class CBTrainer(CustomTrainer):\n",
    "    def __init__(self, *args, beta=0.99, gamma=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cb_loss = CBFocalLoss(samples_per_cls,\n",
    "                                   beta=beta, gamma=gamma)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits  = outputs.logits\n",
    "        loss    = self.cb_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "beta_grid  = [0.9, 0.99]\n",
    "gamma_grid = [1.0, 2.0]\n",
    "seeds      = [42, 52, 62, 88, 99]\n",
    "\n",
    "cb_results = []\n",
    "\n",
    "for beta in beta_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        for seed in seeds:\n",
    "            print(f\"\\n=== CB‑Focal: beta={beta}, gamma={gamma}, seed={seed} ===\")\n",
    "\n",
    "            # reproducibility\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n",
    "\n",
    "            trainer = CBTrainer(\n",
    "                model=model,\n",
    "                args=args,\n",
    "                train_dataset=train_ds_nocontext,      # response‑only proved strongest\n",
    "                eval_dataset=val_ds_nocontext,\n",
    "                compute_metrics=compute_metrics,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "            )\n",
    "\n",
    "            trainer.train()\n",
    "            metrics = trainer.evaluate()\n",
    "\n",
    "            cb_results.append({\n",
    "                \"beta\": beta,\n",
    "                \"gamma\": gamma,\n",
    "                \"seed\": seed,\n",
    "                \"loss\": metrics.get(\"eval_loss\", -1),\n",
    "                \"macro_f1\": metrics.get(\"eval_macro_f1\", -1),\n",
    "                \"lenient_f1\": metrics.get(\"eval_lenient_f1\", -1),\n",
    "                \"accuracy\": metrics.get(\"eval_accuracy\", -1),\n",
    "                \"lenient_accuracy\": metrics.get(\"eval_lenient_accuracy\", -1)\n",
    "            })\n",
    "\n",
    "df_cb = pd.DataFrame(cb_results)\n",
    "df_cb.to_csv(\"results_cb_focal.csv\", index=False)\n",
    "display(df_cb.groupby([\"beta\", \"gamma\"]).agg({\"macro_f1\":\"mean\"}).sort_values(\"macro_f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324a2f0-f913-4a40-a057-0479dd4c6b73",
   "metadata": {},
   "source": [
    "deci nu prea relevant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
